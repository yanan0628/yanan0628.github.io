<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="study for goal">
<meta property="og:type" content="website">
<meta property="og:title" content="Meteor">
<meta property="og:url" content="/index.html">
<meta property="og:site_name" content="Meteor">
<meta property="og:description" content="study for goal">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Meteor">
<meta name="twitter:description" content="study for goal">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>

  <title> Meteor </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Meteor</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/22/9.2).redis工具使用/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-22T15:53:44+08:00" content="2017-08-22">
              2017-08-22
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="redis工具使用"><a href="#redis工具使用" class="headerlink" title="redis工具使用"></a>redis工具使用</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line">环境准备:（注:不同redis版本可能会有差异）</div><div class="line"></div><div class="line">1.redis-server -v</div><div class="line">Redis server v=3.0.7 sha=00000000:0 malloc=jemalloc-3.6.0 bits=64 build=fde71d6d37f8bceb</div><div class="line"></div><div class="line">2.python -V </div><div class="line">Python 2.7.3</div><div class="line">下载：wget https://www.python.org/ftp/python/2.7.3/Python-2.7.3.tar.bz2</div><div class="line">(下载:wget http://index.tv.sohuno.com/software/Python-2.7.3.tar.bz2)</div><div class="line">which python:查看python安装目录</div><div class="line">/usr/local/bin/python</div><div class="line"></div><div class="line">[@fl bin]# python -V</div><div class="line">Python 3.4.1</div><div class="line">[@fl bin]# cd /usr/bin</div><div class="line">[@fl bin]# ll | grep python</div><div class="line">-rwxr-xr-x    1 root root      10920 May 16  2012 abrt-action-analyze-python</div><div class="line">lrwxrwxrwx    1 root root         24 Aug 22 16:19 python -&gt; /usr/local/bin/python2.7</div><div class="line">lrwxrwxrwx.   1 root root          6 Sep 26  2014 python2 -&gt; python</div><div class="line">-rwxr-xr-x    2 root root       9032 May  2  2012 python2.6</div><div class="line">-rwxr-xr-x    2 root root       9032 May  2  2012 python2.6.6</div><div class="line">[@fl bin]# which python</div><div class="line">/usr/local/bin/python</div><div class="line">[@fl bin]# cd /usr/local/bin/</div><div class="line">[@fl bin]# ll | grep python</div><div class="line">lrwxrwxrwx 1 root root      24 Feb 22  2016 python -&gt; /usr/local/bin/python3.4</div><div class="line">lrwxrwxrwx 1 root root       9 Feb 13  2016 python2 -&gt; python2.7</div><div class="line">-rwxr-xr-x 1 root root 6162257 Feb 13  2016 python2.7</div><div class="line">-rwxr-xr-x 1 root root    1624 Feb 13  2016 python2.7-config</div><div class="line">lrwxrwxrwx 1 root root      16 Feb 13  2016 python2-config -&gt; python2.7-config</div><div class="line">lrwxrwxrwx 1 root root       9 Feb 22  2016 python3 -&gt; python3.4</div><div class="line">-rwxr-xr-x 2 root root 8773578 Feb 22  2016 python3.4</div><div class="line">lrwxrwxrwx 1 root root      17 Feb 22  2016 python3.4-config -&gt; python3.4m-config</div><div class="line">-rwxr-xr-x 2 root root 8773578 Feb 22  2016 python3.4m</div><div class="line">-rwxr-xr-x 1 root root    3049 Feb 22  2016 python3.4m-config</div><div class="line">lrwxrwxrwx 1 root root      16 Feb 22  2016 python3-config -&gt; python3.4-config</div><div class="line">lrwxrwxrwx 1 root root      14 Feb 13  2016 python-config -&gt; python2-config</div><div class="line">[@fl bin]# rm -f python</div><div class="line">[@fl bin]# ln -s /usr/local/bin/python2.7</div><div class="line">python2.7         python2.7-config</div><div class="line">[@fl bin]# ln -s /usr/local/bin/python2.7 python</div><div class="line">[@fl bin]# python -V</div><div class="line">Python 2.7.3</div><div class="line"></div><div class="line">3.python redis安装 rediscluster安装</div><div class="line"></div><div class="line">wget https://github.com/andymccurdy/redis-py/archive/2.10.5.zip</div><div class="line">wget https://github.com/Grokzen/redis-py-cluster/releases/download/1.3.4/redis-py-cluster-1.3.4.tar.gz</div><div class="line"></div><div class="line">python setup.py install</div><div class="line"></div><div class="line">4. 导入包</div><div class="line"></div><div class="line">import redis</div><div class="line">import rediscluster</div><div class="line">import sys</div></pre></td></tr></table></figure>
<h2 id="python工具使用"><a href="#python工具使用" class="headerlink" title="python工具使用"></a>python工具使用</h2><hr>
<p>扫描scan key</p>
<hr>
<ul>
<li>单机</li>
</ul>
<p>格式:python scankey.py ip port pattern password</p>
<p>python scankey.py 10.16.14.182 6380 hash<em> “”<br>python scankey.py 10.16.14.182 6380 hash</em> “123”</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">import redis</div><div class="line">import rediscluster</div><div class="line">import sys</div><div class="line"></div><div class="line">def findInstancePatternKeys(host, port, pattern, password):</div><div class="line">    client = redis.StrictRedis(host=host, port=port, password=password)</div><div class="line">    pipeline = client.pipeline(transaction=False)</div><div class="line">    cursor = 0</div><div class="line">    print &quot;====================check &#123;host&#125;:&#123;port&#125;&quot;.format(host=host,port=port)</div><div class="line">    while True:</div><div class="line">        currentCursor, keys = client.scan(cursor=cursor, match=pattern, count=100)</div><div class="line">        if len(keys) &gt; 0:</div><div class="line">            for key in keys:</div><div class="line">              print &quot;key=&#123;key&#125;&quot;.format(key=key)</div><div class="line">            pipeline.execute()</div><div class="line">        cursor = currentCursor</div><div class="line">        if cursor == 0:</div><div class="line">            break</div><div class="line"></div><div class="line">findInstancePatternKeys(sys.argv[1],sys.argv[2],sys.argv[3],sys.argv[4])</div></pre></td></tr></table></figure>
<ul>
<li>集群</li>
</ul>
<p>格式:python scankey.py ip port pattern password</p>
<p>python cluster-scankey.py 10.16.14.182 6380 hash<em> “”<br>python cluster-scankey.py 10.16.14.182 6380 hash</em> “123”</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">import redis</div><div class="line">import rediscluster</div><div class="line">import sys</div><div class="line"></div><div class="line">def findClusterPatternKey(startupNodes, pattern,password):</div><div class="line">    clusterClient = rediscluster.StrictRedisCluster(startup_nodes=startupNodes,password=password, decode_responses=True)</div><div class="line">    clusterInfos = clusterClient.cluster_nodes()</div><div class="line">    for clusternode in clusterInfos:</div><div class="line">        slots = clusternode[&quot;slots&quot;]</div><div class="line">        # only check master</div><div class="line">        if len(slots) &gt; 0:</div><div class="line">            print &quot;========= check &#123;host&#125;:&#123;port&#125;&quot;.format(host=clusternode[&quot;host&quot;],port=clusternode[&quot;port&quot;])</div><div class="line">            findInstancePatternKeys(clusternode[&quot;host&quot;], clusternode[&quot;port&quot;], pattern, password)</div><div class="line"></div><div class="line">def findInstancePatternKeys(host, port, pattern, password):</div><div class="line">    client = redis.StrictRedis(host=host, port=port, password=password)</div><div class="line">    pipeline = client.pipeline(transaction=False)</div><div class="line">    cursor = 0</div><div class="line">    while True:</div><div class="line">        currentCursor, keys = client.scan(cursor=cursor, match=pattern, count=100)</div><div class="line">        if len(keys) &gt; 0:</div><div class="line">            for key in keys:</div><div class="line">                print &quot;key=&#123;key&#125;&quot;.format(key=key)</div><div class="line">            pipeline.execute()</div><div class="line">        cursor = currentCursor</div><div class="line">        if cursor == 0:</div><div class="line">            break</div><div class="line"></div><div class="line">startupNodes = [&#123;&quot;host&quot;:sys.argv[1],&quot;port&quot;:int(sys.argv[2])&#125;]</div><div class="line">findClusterPatternKey(startupNodes, sys.argv[3],sys.argv[4])</div></pre></td></tr></table></figure>
<hr>
<p>扫描 idle key</p>
<hr>
<ul>
<li>单机</li>
</ul>
<p>格式:python scankey.py ip port idleDay password</p>
<p>python scankey.py 10.16.14.182 6380 1 “”<br>python scankey.py 10.16.14.182 6380 1 “123”</p>
<ul>
<li>集群</li>
</ul>
<p>格式:python scankey.py ip port pattern password</p>
<p>python scankey.py 10.16.14.182 6380 hash<em> “”<br>python scankey.py 10.16.14.182 6380 hash</em> “123”</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/21/9.1).redis运维-docker机器用户权限篡改/" itemprop="url">
                  docker机器篡改用户uid
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-21T10:37:35+08:00" content="2017-08-21">
              2017-08-21
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/cachecloud/" itemprop="url" rel="index">
                    <span itemprop="name">cachecloud</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="docker机器篡改用户uid"><a href="#docker机器篡改用户uid" class="headerlink" title="docker机器篡改用户uid"></a>docker机器篡改用户uid</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">1.原因描述：</div><div class="line">cachecloud管理机器：默认创建用户 cachecloud 内网(cachecloud-open 开源用户)，系统默认分配uid为500以上，位于同一台物理机的容器同样的uid用户太多就会超出用户资源资源超出了，系统就会去修改原来的uid。最好指定下吧，范围最好是500以内的，docker这个用户隔离做的弱。</div><div class="line"></div><div class="line">2.查看用户名的uid</div><div class="line">cat /etc/passwd | grep cachecloud  </div><div class="line">cachecloud:x:504:504::/home/cachecloud:/bin/bash （cachecloud与uid=507绑定）</div><div class="line">启动redis实例 则以cachecloud用户进程启动，ps 查看第一列其实就是以504 uid启动</div><div class="line">[@expon-9 /data/cachecloud]# ps -ef | grep redis</div><div class="line">504       3724     1  0 May25 ?        01:36:07 redis-server 0.0.0.0:6381 [cluster]</div><div class="line">504       4705     1  0 Jun12 ?        01:55:42 redis-server *:6385 [sentinel]</div><div class="line">504       7647     1  0 May25 ?        01:50:45 redis-server 0.0.0.0:6383 [cluster]</div><div class="line">504       7695     1  0 May25 ?        01:57:46 redis-server 0.0.0.0:6384 [cluster]</div><div class="line"></div><div class="line">3.指定uid</div><div class="line">创建指定用户uid:useradd -u $&#123;uid&#125;</div><div class="line">修改指定用户uid:usermod -u $&#123;uid&#125;</div></pre></td></tr></table></figure>
<h2 id="1-问题来由"><a href="#1-问题来由" class="headerlink" title="1. 问题来由"></a>1. 问题来由</h2><h3 id="1-1-cachecloud异常日志"><a href="#1-1-cachecloud异常日志" class="headerlink" title="1.1 cachecloud异常日志"></a>1.1 cachecloud异常日志</h3><p>发现cachecloud报警 超时，查看cc的errlog，发现有大量的机器ssh通信失败(收集机器指标)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">2017-08-19 01:20:28.408 &#123;machine-pool-thread-74&#125; ERROR com.sohu.cache.server.nmon.NMONService - start nmon 10.10.193.187 err:bash: </div><div class="line">/opt/cachecloud/soft/nmon: Permission denied</div><div class="line">659 2017-08-19 01:20:28.462 &#123;SSH-163&#125; ERROR com.sohu.cache.ssh.SSHTemplate - </div><div class="line">address 10.10.193.187:22 execute cmd:([ -e &quot;/opt/cachecloud/soft/nmon&quot; ] &amp;&amp; /</div><div class="line">opt/cachecloud/soft/nmon -V), err:bash: /opt/ cachecloud/soft/nmon: Permission denied</div></pre></td></tr></table></figure>
<h3 id="1-2-发现目录权限变更"><a href="#1-2-发现目录权限变更" class="headerlink" title="1.2 发现目录权限变更"></a>1.2 发现目录权限变更</h3><ul>
<li><p>目录用户从属：cachecloud现在变更为504,不是cachecloud用户无法收集机器数据(说明cachecloud uid=504 绑定失败)</p>
</li>
<li><p>查看cachecloud用户uid：cachecloud:x:285:504::/home/cachecloud:/bin/bash(cachecloud新的uid 为285)</p>
<p>  <img src="http://i3.itc.cn/20170823/aac_a71c82ee_a822_fff4_d1b7_1b122cc7b511_1.png" alt=""></p>
</li>
</ul>
<h3 id="1-3-赋权限给目录"><a href="#1-3-赋权限给目录" class="headerlink" title="1.3 赋权限给目录"></a>1.3 赋权限给目录</h3><p>执行chown -R cachecloud:cachecloud /opt/cachecloud 给目录赋权限，ssh通信正常，但是现在cachecloud用户id 为285</p>
<h3 id="1-4-ps查看redis启动进程的uid"><a href="#1-4-ps查看redis启动进程的uid" class="headerlink" title="1.4 ps查看redis启动进程的uid"></a>1.4 ps查看redis启动进程的uid</h3><p>redis后台进程uid仍然是504，和上面cachecloud(uid=285）不一致</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ps -ef | grep redis </div><div class="line">504 9706 1 0 Jul26 ? 00:54:26 redis-server *:6379 [cluster]</div><div class="line">504 9792 1 0 Jul26 ? 01:05:04 redis-server *:6380 [cluster]</div></pre></td></tr></table></figure>
<h3 id="1-5-redis启动用户uid和目录用户uid权限不一致"><a href="#1-5-redis启动用户uid和目录用户uid权限不一致" class="headerlink" title="1.5 redis启动用户uid和目录用户uid权限不一致"></a>1.5 redis启动用户uid和目录用户uid权限不一致</h3><blockquote>
<p>权限不一致，会导致以下问题：</p>
</blockquote>
<ul>
<li>aof文件剧增，重写失败导致文件过大 aof_current_size 尺寸过大 (出现大量报警)，还有部分节点状态 变为 心跳停止</li>
<li>redis日志：(大量权限异常 日志文件剧增)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[root@10 logs]# tail -f redis-6389-201701191612.log</div><div class="line">    32124:M 20 Aug 22:55:27.248 # Background AOF rewrite terminated with error</div><div class="line">    32124:M 20 Aug 22:55:27.348 * Starting automatic rewriting of AOF on 2987% growth</div><div class="line">    32124:M 20 Aug 22:55:27.422 * Background append only file rewriting started by pid 25156</div><div class="line">    25156:C 20 Aug 22:55:27.422 # Opening the temp file for AOF rewrite in rewriteAppendOnlyFile(): Permission denied</div><div class="line">    32124:M 20 Aug 22:55:27.523 # Background AOF rewrite terminated with error</div><div class="line">    32124:M 20 Aug 22:55:27.624 * Starting automatic rewriting of AOF on 2987% growth</div><div class="line">    32124:M 20 Aug 22:55:27.697 * Background append only file rewriting started by pid 25159</div><div class="line">    25159:C 20 Aug 22:55:27.697 # Opening the temp file for AOF rewrite in rewriteAppendOnlyFile(): Permission denied</div><div class="line">    32124:M 20 Aug 22:55:27.798 # Background AOF rewrite terminated with error</div><div class="line">    32124:M 20 Aug 22:55:27.899 * Starting automatic rewriting of AOF on 2987% growth</div></pre></td></tr></table></figure>
<h2 id="2-篡改用户uid处理"><a href="#2-篡改用户uid处理" class="headerlink" title="2.篡改用户uid处理"></a>2.篡改用户uid处理</h2><h3 id="2-1-passwd相关参数解释"><a href="#2-1-passwd相关参数解释" class="headerlink" title="2.1 passwd相关参数解释"></a>2.1 passwd相关参数解释</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">执行cat /etc/passwd | grep cachecloudc查看cacheloud用户uid</div><div class="line">uid:285 gid:504 (第一次创建用户时 gid=uid=504)</div><div class="line"></div><div class="line">cachecloud:x:285:504::/home/cachecloud:/bin/bash</div><div class="line">LOGNAME:PASSWORD:UID:GID:USERINFO:HOME:SHELL</div><div class="line">用户名 :密码:用户标识号:组标识号:用户名:用户主目录:命令解释程序</div></pre></td></tr></table></figure>
<h3 id="2-2-被篡改uid原因分析"><a href="#2-2-被篡改uid原因分析" class="headerlink" title="2.2 被篡改uid原因分析"></a>2.2 被篡改uid原因分析</h3><p>docker机器引起，原因分析：</p>
<pre><code>1.默认分配的UID:GID是一致,当前用户uid=gid=504，如果在创建用户过程中，不指定
  useradd -u ${uid},系统会自动分配大于500的uid
2.当前机器uid已被修改为285，此时 cachecloud 与uid=504 绑定失效，目录显示原有
  cachecloud用户id：504
3.执行完chown -R cachecloud:cachecloud /opt/cachecloud，此时目录用户为
  cachecoud ，但此时cachecloud用户与uid=285绑定
4.此时redis重写aof 出现大量权限失败异常，解决办法参考2.3
</code></pre><h3 id="2-3-解决办法"><a href="#2-3-解决办法" class="headerlink" title="2.3 解决办法"></a>2.3 解决办法</h3><ul>
<li><p>1.重启redis（uid会重新绑定）</p>
</li>
<li><p>2.不重启redis,在线配置用户uid</p>
<pre><code>1:确认redis进程的uid
    ps -ef | grep redis
    504      27534     1  1  2016 ?        5-13:15:33 redis-server *:6380 [cluster]
    504      27619     1  1  2016 ?        5-03:46:29 redis-server *:6381 [cluster]
    504      27703     1  1  2016 ?        5-10:25:36 redis-server *:6382 [cluster]
    504      27788     1  0  2016 ?        1-19:20:19 redis-server *:6383 [cluster]
    第一列504为uid

2:确认用户cachecloud的uid
    cat /etc/passwd | grep cachecloud
    cachecloud:x:285:504::/home/cachecloud:/bin/bash
    当前uid为285，需要重置用户uid

3:修改用户的uid
    usermod -u 504 cachecloud

4:修改目录属主
    chown -R cachecloud:cachecloud /opt/cachecloud

5.确认用户uid：
    cat /etc/passwd | grep cachecloud
    cachecloud:x:504:504::/home/cachecloud:/bin/bash

查看top：
PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
28793 cachecloud  20   0 3314m 1.9g  424 R 71.2  0.8   0:05.02 redis-server
28796 cachecloud  20   0 3394m 2.0g  420 R 70.9  0.8   0:04.86 redis-server    
</code></pre></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/06/(8.5).JAVA虚拟机(五)-JVM性能调优及故障排查/" itemprop="url">
                  java虚拟机-故障排查
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-08-06T16:37:35+08:00" content="2016-08-06">
              2016-08-06
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JVM</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="JVM常见问题及性能分析"><a href="#JVM常见问题及性能分析" class="headerlink" title="JVM常见问题及性能分析"></a>JVM常见问题及性能分析</h2><p>你遇到过这些问题吗？</p>
<pre><code>OOM: Heap, Stack, Perm
系统频繁GC
Java进程占用CPU过高
Java占用内存增长很快
远程调用timeout
系统响应时间变长，越来越慢
……
</code></pre><h3 id="方法一：GC-log"><a href="#方法一：GC-log" class="headerlink" title="方法一：GC log"></a>方法一：GC log</h3><ul>
<li>1.开启GC日志：-XX:+PrintGCDetails (包含-XX:+PrintGC -verbose:gc )</li>
<li>2.GC触发时间：-XX:+PrintGCDateStamps/-XX:+PrintGCTimeStamps </li>
<li><p>3.日志存放位置：-Xloggc:/path/gc.log</p>
<pre><code>配置JVM参数：
-XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps 
-Xloggc:D:/logs/gc/gc.log 
</code></pre></li>
</ul>
<p>输出日志：</p>
<p>2016-03-08T16:11:05.446+0800: 8.861: [GC2016-03-08T16:11:05.446+0800: 8.861: [ParNew: 46080K-&gt;5120K(46080K), 0.0177669 secs] 66765K-&gt;28892K(97280K), 0.0178659 secs] [Times: user=0.03 sys=0.00, real=0.02 secs]<br>2016-03-08T17:01:01.930+0800: 375.874: [Full GC2016-03-08T17:01:01.930+0800: 375.874: [CMS: 40535K-&gt;40535K(51200K), 0.1600130 secs] 79475K-&gt;59991K(97280K), [CMS Perm : 36535K-&gt;36535K(51200K)], 0.1601362 secs] [Times: user=0.16 sys=0.00, real=0.16 secs] </p>
<p>可参考：</p>
<p>官网：<a href="https://blogs.oracle.com/poonam/entry/understanding_cms_gc_logs" target="_blank" rel="external">https://blogs.oracle.com/poonam/entry/understanding_cms_gc_logs</a></p>
<p>并发编程网：<a href="http://ifeve.com/jvm-cms-log/" target="_blank" rel="external">http://ifeve.com/jvm-cms-log/</a></p>
<h3 id="方法二：jdk自带命令"><a href="#方法二：jdk自带命令" class="headerlink" title="方法二：jdk自带命令"></a>方法二：jdk自带命令</h3><pre><code>jps  ： jps可以理解为java的ps，用于显示java进程 ,-v 输出虚拟机启动的时的参数   
        jps –v pid       
jinfo：jinfo查看和调整虚拟机的各项参数   
        jinfo  pid
jmap ：jmap生成堆转存快照文件
        jmap –heap pid显示Java堆详细信息，如使用哪种回收器，参数配置、分代状况
jstat：jstat 统计信息监视工具
       jstat –gcutil pid  主要关注已使用空间占总空间的百分比
jstack：jstack生成当前时刻线程快照
        jstack pid 
         检测cpu使用率飙高时三个步骤： 
           1.查该进程最高的线程  top –Hp pid
           2.转换最高线程id 为16进程
           3.查看堆栈对应线程id的堆栈信息
</code></pre><blockquote>
<p>性能调试：</p>
</blockquote>
<pre><code>cd `dirname $0`
PID=$1
BIN_DIR=`pwd`
cd $BIN_DIR
DUMP_DIR=./
DUMP_DATE=`date +%Y%m%d%H%M%S`
DATE_DIR=$DUMP_DIR/$DUMP_DATE
if [ ! -d $DATE_DIR ]; then
        mkdir $DATE_DIR
fi

echo -e &quot;Dumping the jdump ...\c&quot;
jstack $PID &gt; $DATE_DIR/jstack-$PID.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
jinfo $PID &gt; $DATE_DIR/jinfo-$PID.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
jstat -gcutil $PID &gt; $DATE_DIR/jstat-gcutil-$PID.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
jstat -gccapacity $PID &gt; $DATE_DIR/jstat-gccapacity-$PID.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
jmap $PID &gt; $DATE_DIR/jmap-$PID.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
jmap -heap $PID &gt; $DATE_DIR/jmap-heap-$PID.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
jmap -histo $PID &gt; $DATE_DIR/jmap-histo-$PID.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
if [ -r /usr/sbin/lsof ]; then
/usr/sbin/lsof -p $PID &gt; $DATE_DIR/lsof-$PID.dump
echo -e &quot;.\c&quot;
fi

if [ -r /bin/netstat ]; then
/bin/netstat -an &gt; $DATE_DIR/netstat.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
fi
if [ -r /usr/bin/iostat ]; then
/usr/bin/iostat &gt; $DATE_DIR/iostat.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
fi
if [ -r /usr/bin/mpstat ]; then
/usr/bin/mpstat -P ALL &gt; $DATE_DIR/mpstat.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
fi
if [ -r /usr/bin/vmstat ]; then
/usr/bin/vmstat &gt; $DATE_DIR/vmstat.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
fi
if [ -r /usr/bin/free ]; then
/usr/bin/free -t &gt; $DATE_DIR/free.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
fi
if [ -r /usr/bin/sar ]; then
/usr/bin/sar &gt; $DATE_DIR/sar.dump 2&gt;&amp;1
echo -e &quot;.\c&quot;
fi
if [ -r /usr/bin/uptime
</code></pre><h3 id="方法三：java工具分析"><a href="#方法三：java工具分析" class="headerlink" title="方法三：java工具分析"></a>方法三：java工具分析</h3><p>Jconsole/JvisualVM/Jprofile/Jmc 等工具对 操作系统(cpu/线程数/内存) 以及jvm分代消耗 gc情况 或 死锁 或 Mbean jmx监控 着手分析</p>
<h2 id="如何进行系统调优"><a href="#如何进行系统调优" class="headerlink" title="如何进行系统调优"></a>如何进行系统调优</h2><h3 id="考虑哪些方面"><a href="#考虑哪些方面" class="headerlink" title="考虑哪些方面"></a>考虑哪些方面</h3><ul>
<li>硬件:<br>  网卡/网络是否通/交换机</li>
<li>操作系统:<br>  负载load/内存mem/swap/io</li>
<li>运行环境软件:<br>  Nginx/Apache/Resin<br>  JVM参数</li>
<li>应用本身<br>  Java程序</li>
</ul>
<pre><code>调查系统现状/寻找性能瓶颈/定位问题
    请求次数
    响应时间
资源消耗：CPU/内存/文件/网络
    确定调优目标
    单机用户量=用户量/机器数
     并发目标：如95%用户500ms响应
定位资源消耗
    -在哪里
        CPU/内存/文件/网络
    -什么类型
        线程调度太频繁
        线程load太高
        Full GC太频繁
        Full GC时间过长
        文件读写太慢、堵塞
定位问题代码
    使用Java工具分析内存、线程
    优化问题代码
    未来：编写高效代码 
</code></pre><h3 id="系统分析"><a href="#系统分析" class="headerlink" title="系统分析"></a>系统分析</h3><blockquote>
<p>cpu消耗分析</p>
</blockquote>
<p>上下文切换：文件IO、网络IO、锁、Sleep<br>运行队列（load）：每个核任务队列，最好1~3<br>利用率（关键指标）：进程、内核、中断处理、IO等待、空闲<br>top命令<br>top按进程显示<br>top –p 29974按进程ID显示<br>top1按核显示<br>topshift+h按线程显示<br>vmstat采样<br>vmstat -1每1秒采样</p>
<p>tsar历史消耗对比</p>
<pre><code>top参数意义
 us用户进程任务：高是线程粒度太大，线程一直处于可运行状态Runabble
     原因1：线程无阻塞、循环、大计算（正则、纯粹大运算）
     原因2：频繁GC(Eden/Old小，新对象占用内存多，YoungGC/Full GC)
定位线程：top -5650shift+h找到线程号26697， 0x6849
       一个线程总占用高： jstack 26697 | grep ‘nid=0x6849’
    多个线程来回切换无法定位：jstack 26697
sy内核线程切换：高是线程太多粒度太小
原因：不断阻塞切换、锁等待、IO等待
定位线程： jstack -l 26697，分析等待状态、锁竞争过多线程
ni为nice改变优先级，id空闲时间
wa等待io：大文件
hi硬件中断：网卡接收数据频繁等
si软件中断

top - 16:57:02 up 98 days,  1:40,  9 users,  load average: 7.71, 9.08, 11.05
Tasks: 279 total,   1 running, 277 sleeping,   0 stopped,   1 zombie
Cpu(s): 27.4%us,  5.1%sy,  0.0%ni, 65.6%id,  1.8%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  65981472k total, 49901984k used, 16079488k free,  4359276k buffers
Swap:  4192956k total,        0k used,  4192956k free, 23197812k cached
</code></pre><blockquote>
<p>内存消耗分析</p>
</blockquote>
<p>vmstat<br>swpd已用虚拟内存kb：过高表示物理内存不够用<br>原因：JVM内存设置过大，Java线程过多，ByteBuffer过多—-即可定位<br>free空闲物理内存<br>buff用作缓冲内存<br>cache用作缓存内存<br>si每秒从disk读至内存数据量<br>so每秒从内存挟制disk数据量</p>
<pre><code>procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  3      0 15973668 4359360 23257704    0    0     0   123    0    0 27  5 66  2  0
 0  2      0 15974188 4359360 23257732    0    0     0  5092 1878 3922  0  0 93  6  0

swap相关：kbswpfree,kbswpused
物理内存：kbmemfree,kbmemused
实际可用=kbmemfree+kbfuffers缓冲+kbcached缓存

10时00分01秒 kbmemfree kbmemused  %memused kbbuffers  kbcached kbswpfree kbswpused  %swpused  kbswpcad
10时10分01秒  18004796  47976676     72.71   4354120  21700168   4192956         0      0.00         0
10时20分01秒  17919088  48062384     72.84   4354152  21746360   4192956         0      0.00         0

top：显示的是实际占用内存=Heap+Stack+Perm+ByteBuffer

vmstat/sar/top对比
sar优点：比vmstat，可分析历史
vmstat/sar弱点：不能分析进程内存，top可以
top弱点：不易分析实际占用内存
</code></pre><blockquote>
<p>文件IO消耗分析</p>
</blockquote>
<p>iostat -x<br>iowait每次IO等待CPU比例，高是因为一直等不到IO<br>原因1：文件读写文件占用时间长，多个线程需要大量写入（如频繁写日志）<br>原因2：磁盘设备处理速度慢<br>原因3：文件系统慢<br>原因4：操作文件太大<br>定位线程：jstack找到runnable中的线程<br>tps每秒IO请求数<br>Blk_read/s每秒读区块数(512byte)<br>Blk_wrtn/s每秒写区块数<br>Blk_read读区块总数<br>Blk_wrtn写区块总数</p>
<pre><code>avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           2.54    0.00    0.55    0.03    0.00   96.87

Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
sda              11.17        41.40       417.44  436437014 4400574548
sda1              1.11         0.13        37.17    1356426  391818168
sda2              0.00         0.00         0.00       1424          0
sda3              2.64         1.02        35.43   10714778  373487500
sda4              0.00         0.00         0.00          8          0
sda5              0.65         0.66        23.25    6921378  245057640
sda6              6.78        39.60       321.60  417442456 3390211240

采样iostat -x xvda 3 5
r/s每秒读的请求数
r/s每秒写的请求书
avgqu-sz等待请求队列的平均长度
await每次IO等待时间ms
svctm平均每次设备执行IO操作时间

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
       2.54    0.00    0.55    0.03    0.00   96.87

Device:         rrqm/s   wrqm/s   r/s   w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util
sda               0.13    41.63  0.61 10.56    41.39   417.55    41.07     0.03    2.58   0.32   0.36
sda1              0.01     3.54  0.00  1.11     0.13    37.17    33.58     0.00    1.01   0.31   0.03
sda2              0.00     0.00  0.00  0.00     0.00     0.00    54.77     0.00    5.08   4.62   0.00
sda3              0.02     1.81  0.02  2.62     1.02    35.43    13.83     0.00    0.30   0.20   0.05
sda4              0.00     0.00  0.00  0.00     0.00     0.00     2.00     0.00   12.00  12.00   0.00
sda5              0.01     2.29  0.03  0.62     0.66    23.25    36.71     0.00    0.98   0.37   0.02
sda6              0.10    33.99  0.56  6.22    39.59   321.69    53.32     0.03    3.88   0.42   0.28
</code></pre><blockquote>
<p>网络IO消耗分析</p>
</blockquote>
<p>cat /proc/interrupts：查看网卡中断是否均衡分配到各CPU<br>只分配到一个CPU：修改kernel，或用支持MSI-X网卡<br>tcpdump -i eth0 -s 0 -l -w - dst port 11214 | strings | grep test_<br>sar -n ALL 1 2：统计收发包成功失败数量<br>网卡成功接包、发包信息<br>网卡失败接包、发包信息(ping)<br>socket统计信息</p>
<pre><code>18时38分08秒     IFACE   rxpck/s   txpck/s   rxbyt/s   txbyt/s   rxcmp/s   txcmp/s  rxmcst/s
18时38分09秒        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00
18时38分09秒      eth0    581.00    703.00 107914.00  89316.00      0.00      0.00      0.00
18时38分09秒      eth1      8.00      0.00    512.00      0.00      0.00      0.00      0.00
18时38分09秒      usb0      0.00      0.00      0.00      0.00      0.00      0.00      0.00

18时38分08秒     IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s
18时38分09秒        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
18时38分09秒      eth0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
18时38分09秒      eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
18时38分09秒      usb0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

18时38分08秒    call/s retrans/s    read/s   write/s  access/s  getatt/s
18时38分09秒      0.00      0.00      0.00      0.00      0.00      0.00
</code></pre><h2 id="命令分析"><a href="#命令分析" class="headerlink" title="命令分析"></a>命令分析</h2><p>堆栈分析线程状态(blocked，time_waiting, Waiting)<br>可参考：<a href="http://www.cnblogs.com/zhengyun_ustc/archive/2013/03/18/tda.html" target="_blank" rel="external">http://www.cnblogs.com/zhengyun_ustc/archive/2013/03/18/tda.html</a></p>
<h3 id="线程状态查看"><a href="#线程状态查看" class="headerlink" title="线程状态查看"></a>线程状态查看</h3><p>jstack 21415 | grep -i “java.lang.Thread.State” | sort | uniq -c</p>
<pre><code>13    java.lang.Thread.State: BLOCKED (on object monitor)
 21    java.lang.Thread.State: RUNNABLE
 70    java.lang.Thread.State: TIMED_WAITING (on object monitor)
  4    java.lang.Thread.State: TIMED_WAITING (parking)
  6    java.lang.Thread.State: TIMED_WAITING (sleeping)
 13    java.lang.Thread.State: WAITING (on object monitor)
</code></pre><h3 id="输出jstack日志"><a href="#输出jstack日志" class="headerlink" title="输出jstack日志"></a>输出jstack日志</h3><p>jstack 21415 &gt; jstack.log</p>
<h3 id="查看jstack-BLOCKED状态的锁"><a href="#查看jstack-BLOCKED状态的锁" class="headerlink" title="查看jstack BLOCKED状态的锁"></a>查看jstack BLOCKED状态的锁</h3><p>vim jstack.log</p>
<pre><code>&quot;http--8082-16$1500284796&quot; daemon prio=10 tid=0x00002aabd5f57000 nid=0x5902 waiting for monitor entry [0x0000000043829000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:388)
        - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
        at java.net.ServerSocket.implAccept(ServerSocket.java:453)
        at java.net.ServerSocket.accept(ServerSocket.java:421)
        at com.caucho.vfs.QServerSocketWrapper.accept(QServerSocketWrapper.java:91)
        at com.caucho.server.port.Port.accept(Port.java:1179)
        at com.caucho.server.port.TcpConnection.run(TcpConnection.java:659)
        at com.caucho.util.ThreadPool$Item.runTasks(ThreadPool.java:743)
        at com.caucho.util.ThreadPool$Item.run(ThreadPool.java:662)
        at java.lang.Thread.run(Thread.java:619)
</code></pre><h3 id="查看锁的状态-0x00002aab14c63d10"><a href="#查看锁的状态-0x00002aab14c63d10" class="headerlink" title="查看锁的状态 0x00002aab14c63d10"></a>查看锁的状态 0x00002aab14c63d10</h3><pre><code>[@zjm_106_165 ~]# cat jstack.log.20160719 | grep 0x00002aab14c63d10
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - locked &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
    - waiting to lock &lt;0x00002aab14c63d10&gt; (a java.net.SocksSocketImpl)
</code></pre><h2 id="工具使用"><a href="#工具使用" class="headerlink" title="工具使用"></a>工具使用</h2><h3 id="tsar"><a href="#tsar" class="headerlink" title="tsar"></a>tsar</h3><h3 id="iftop"><a href="#iftop" class="headerlink" title="iftop"></a>iftop</h3>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/05/(8.6).JAVA虚拟机(六)-JMM内存模型/" itemprop="url">
                  JMM内存模型
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-08-05T16:37:35+08:00" content="2016-08-05">
              2016-08-05
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JVM</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/04/(8.4).JAVA虚拟机(四)-G1垃圾回收器/" itemprop="url">
                  G1 Heap Stucture
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-08-04T16:37:35+08:00" content="2016-08-04">
              2016-08-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JVM</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="The-G1-Garbage-Collector-垃圾优先型垃圾回收器"><a href="#The-G1-Garbage-Collector-垃圾优先型垃圾回收器" class="headerlink" title="The G1 Garbage Collector(垃圾优先型垃圾回收器)"></a>The G1 Garbage Collector(垃圾优先型垃圾回收器)</h3><p>The Garbage-First (G1) collector is a server-style garbage collector, targeted for multi-processor machines with large memories. It meets garbage collection (GC) pause time goals with a high probability, while achieving high throughput. The G1 garbage collector is fully supported in Oracle JDK 7 update 4 and later releases. The G1 collector is designed for applications that:</p>
<ul>
<li><p>Can operate concurrently with applications threads like the CMS collector.</p>
<p>  G1像cms收集器一样能够将收集线程和用户线程一起并发处理</p>
</li>
<li><p>Compact free space without lengthy GC induced pause times.</p>
<p>  GC在停顿时间内收集无需要更多的空间    </p>
</li>
<li><p>Need more predictable GC pause durations.</p>
<p>  提供更可靠的GC停顿时间预测</p>
</li>
<li><p>Do not want to sacrifice a lot of throughput performance.</p>
<p>  不想牺牲太多的吞吐量</p>
</li>
<li><p>Do not require a much larger Java heap.</p>
<p>  G1需要一个更大的堆空间，关键建议6G以上</p>
</li>
</ul>
<p>G1 is planned as the long term replacement for the Concurrent Mark-Sweep Collector (CMS). Comparing G1 with CMS, there are differences that make G1 a better solution. One difference is that G1 is a compacting collector. G1 compacts sufficiently to completely avoid the use of fine-grained free lists for allocation, and instead relies on regions. This considerably simplifies parts of the collector, and mostly eliminates potential fragmentation issues. Also, G1 offers more predictable garbage collection pauses than the CMS collector, and allows users to specify desired pause targets.</p>
<p>释义：G1使用并发和并行阶段实现其目标暂停时间，并保持良好的吞吐量,与CMS收集器不同的是，G1回收算法采取的并发-整理 ；它可以解决传统的parNew+CMS垃圾收集算法中,有很多晋代失败(promotion failed)/并发失败(concurrent mode failure),然后做Full gc的问题；G1提供更可预测的垃圾收集停顿比CMS收集器，并允许用户指定所需的停顿的目标。</p>
<blockquote>
<p>相关解释：</p>
</blockquote>
<p>G1收集器之所以能建立可预测的停顿时间模型，是因为他可以<strong>有计划的避免在整个java堆中进行全局与的垃圾收集</strong>。G1跟踪各个region里面垃圾堆积的价值大小(回收所获得的空间大小以及回收所需要时间的经验值)，在后台维护一个优先列表，每次根据允许收集时间，优先回收价值最大的region（这也就是Garbage-First名称的由来）</p>
<ul>
<li>并行和并发：适合并充分利用多CPU，多核环境</li>
<li>分代收集：分region去收集，可避免碎片化问题</li>
<li>空间整合：G1整体是基于Mark-compact 标记-整理，但是从局部 两个 region之间是基于”复制”算法实现</li>
<li>可预测停顿：建立可预测停顿时间，明确指定在一个长度为M毫秒的时间片内，消耗在垃圾收集上的时间不超过N毫秒</li>
</ul>
<h3 id="G1适合场景及特点"><a href="#G1适合场景及特点" class="headerlink" title="G1适合场景及特点"></a>G1适合场景及特点</h3><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><ul>
<li>1)适用在big heap(6GB or larger)场景,不能容忍长时间停顿(Full GC)的服务器场景.</li>
<li>2)有大量存活对象(超过50%)的场景.例如:数据服务器场景.Hbase，Cassandra等.</li>
<li>3)解决传统的parNew+CMS垃圾收集算法中,有很多晋代失败(promotion failed)/并发失败(concurrent mode failure),然后做Full gc..</li>
</ul>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li>1).G1可以控制最长停顿时间(-XX:MaxGCPauseMillis),这是个预计值,G1会根据这个时间制定回收策略,但是设置过低停顿回造成低吞吐。</li>
<li>2).G1基于复制的算法，回收过程不会产生碎片,这是相比CMS最大的优势.</li>
<li>3).G1把heap分割成很多大小相等的区域(region),不再使用固定空间分代的方式，采用逻辑分代:Eden,Survivor,Old。每个逻辑分代含有若干区域且数量可以动态调整.</li>
</ul>
<h4 id="查看分代情况"><a href="#查看分代情况" class="headerlink" title="查看分代情况"></a>查看分代情况</h4><pre><code>通过使用jmap -heap 得到的堆统计信息可以更好的理解逻辑分代:

    Heap Configuration:
       MinHeapFreeRatio = 40
       MaxHeapFreeRatio = 70
       MaxHeapSize      = 25769803776 (24576.0MB)
       NewSize          = 1363144 (1.2999954223632812MB)
       MaxNewSize       = 17592186044415 MB
       OldSize          = 5452592 (5.1999969482421875MB)
       NewRatio         = 2
       SurvivorRatio    = 6
       PermSize         = 100663296 (96.0MB)
       MaxPermSize      = 100663296 (96.0MB)
       G1HeapRegionSize = 8388608 (8.0MB)
    G1 Heap:
       regions  = 3072
       capacity = 25769803776 (24576.0MB)
       used     = 11232244096 (10711.902709960938MB)
       free     = 14537559680 (13864.097290039062MB)
       43.58684370915095% used
    G1 Young Generation:
    Eden Space:
       regions  = 29
       capacity = 1233125376 (1176.0MB)
       used     = 243269632 (232.0MB)
       free     = 989855744 (944.0MB)
       19.727891156462587% used
    Survivor Space:
       regions  = 14
       capacity = 117440512 (112.0MB)
       used     = 117440512 (112.0MB)
       free     = 0 (0.0MB)
       100.0% used
    G1 Old Generation:
       regions  = 1298
       capacity = 24419237888 (23288.0MB)
       used     = 10871533952 (10367.902709960938MB)
       free     = 13547703936 (12920.097290039062MB)
       44.52036546702567% used
</code></pre><h3 id="G1回收过程"><a href="#G1回收过程" class="headerlink" title="G1回收过程"></a>G1回收过程</h3><h4 id="G1-Heap-Structure"><a href="#G1-Heap-Structure" class="headerlink" title="G1 Heap Structure"></a>G1 Heap Structure</h4><ul>
<li>1). G1 Heap Structure<br><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide8.png" alt=""></li>
</ul>
<p>Region size is chosen by the JVM at startup. The JVM generally targets around 2000 regions varying in size from 1 to 32Mb.</p>
<p>G1 GC 启动后把堆被划分成大小相同的多个区域(Region)。区域的大小由(-XX:G1HeapRegionSize)指定,不指定区域大小会从1MB到32MB自动制定,区域大小确定后不会做动态调整.</p>
<ul>
<li><p>2). G1 Heap Allacation<br><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide9.png" alt=""><br>The heap is partitioned into a set of equal-sized heap regions, each a contiguous range of virtual memory. Certain region sets are assigned the same roles (eden, survivor, old) as in the older collectors, but there is not a fixed size for them. This provides greater flexibility in memory usage.</p>
<p>  整个heap划分为Eden,Survivor,Old三个不连续的逻辑区域。<br>运行过程中,G1会为每个Region使用Remembered Set来维护对象引用,<br>应用程序在对Reference类型的数据进行写操作时会产生一个Write Barrier暂时中断写操作，<br>检查Reference引用的对象是否处于不同的Region之中，如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。<br>当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set来避免对全堆扫描.</p>
</li>
</ul>
<h4 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h4><p>G1 Footprint:<br>If you migrate from the ParallelOldGC or CMS collector to G1, you will likely see a larger JVM process size. This is largely related to “accounting” data structures such as Remembered Sets and Collection Sets.</p>
<ul>
<li><p><strong>Remembered Sets</strong>：or RSets track object references into a given region. There is one RSet per region in the heap. The RSet enables the parallel and independent collection of a region. <em>The overall footprint impact of RSets is less than 5%.</em></p>
</li>
<li><p><strong>Collection Sets</strong>:or CSets the set of regions that will be collected in a GC. All live data in a CSet is evacuated (copied/moved) during a GC. Sets of regions can be Eden, survivor, and/or old generation.<em> CSets have a less than 1% impact on the size of the JVM</em></p>
</li>
</ul>
<h4 id="G1收集过程"><a href="#G1收集过程" class="headerlink" title="G1收集过程"></a>G1收集过程</h4><p><img src="http://i3.itc.cn/20160904/aac_cc6377ea_e867_65d5_f0e4_03b27c6f52be_1.jpg" alt=""></p>
<ul>
<li>初始标记(inital Marking)</li>
<li>并发标记(Concurrent Marking)</li>
<li>最终标记(Final Marking)</li>
<li>筛选回收(live Data counting and Evacuation）</li>
</ul>
<p><img src="http://i2.itc.cn/20160904/aac_3d000bc6_44db_e229_78cd_6cde550ccd66_1.png" alt=""></p>
<p>回收过程按回收区域集合(CollectionSets/CSets)划分.CSets可以包含(Eden,survivor/old)中的region,CSets占用内存一般小于整个jvm的1%;<br>年轻代垃圾回收:<br>G1 Young GC同时回收eden区域和上次垃圾回收的存活区域。Eden 和survivor的存活对象被疏散(复制/移动)到新的区域集。<br>被疏散对象的目标区域取决于对象的年龄,达到晋升年龄的对象疏散到老年代区域,<br>否则疏散到存活区,并将它包含在下一次年轻代或混合垃圾回收的CSet中。<br>混合垃圾回收:<br>G1 Mixd GC同时回收Eden,survivor,old的存活区域。当成功完成并发标记周期后，G1 GC从执行年轻代垃圾回收切换为执行混合垃圾回收。<br>在混合垃圾回收期间,G1GC 将一些旧的区域添加到 eden 和存活区供将来回收。G1GC 回收了足够的旧区域后（经过多次混合垃圾回收），<br>G1将恢复执行年轻代垃圾回收,直到下一次标记周期完成。</p>
<h4 id="G1-YoungGC"><a href="#G1-YoungGC" class="headerlink" title="G1 YoungGC"></a>G1 YoungGC</h4><ul>
<li>1.The heap is split into approximately 2000 regions. Minimum size is 1Mb and maximum size is 32Mb. Blue regions hold old generation objects and green regions hold young generation objects.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide10.png" alt=""></p>
<ul>
<li>2.Live objects are evacuated (i.e., copied or moved) to one or more survivor regions. If the aging threshold is met, some of the objects are promoted to old generation regions.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide11.png" alt=""><br>This is a stop the world (STW) pause. Eden size and survivor size is calculated for the next young GC. Accounting information is kept to help calculate the size. Things like the pause time goal are taken into consideration.<br>This approach makes it very easy to resize regions, making them bigger or smaller as needed.</p>
<ul>
<li>3.End of a Young GC with G1,Live objects have been evacuated to survivor regions or to old generation regions.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide12.png" alt=""></p>
<p>Recently promoted objects are shown in dark blue. Survivor regions in green.<br>In summary, the following can be said about the young generation in G1:</p>
<ul>
<li>The heap is a single memory space split into regions.</li>
<li>Young generation memory is composed of a set of non-contiguous regions. This makes it easy to resize when needed.</li>
<li>Young generation garbage collections, or young GCs, are stop the world events. All application threads are stopped for the operation.</li>
<li>The young GC is done in parallel using multiple threads.</li>
<li>Live objects are copied to new survivor or old generation regions.</li>
</ul>
<h4 id="G1-OldGc"><a href="#G1-OldGc" class="headerlink" title="G1 OldGc"></a>G1 OldGc</h4><ul>
<li><ol>
<li><strong>Initial Marking Phase:</strong>Initial marking of live object is piggybacked on a young generation garbage collection. In the logs this is noted as GC pause (young)(inital-mark).</li>
</ol>
</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide13.png" alt=""></p>
<ul>
<li>2.<strong>Concurrent Marking Phase:</strong>If empty regions are found (as denoted by the “X”), they are removed immediately in the Remark phase. Also, “accounting” information that determines liveness is calculated.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide14.png" alt=""></p>
<ul>
<li>3.<strong>Remark Phase:</strong>Empty regions are removed and reclaimed. Region liveness is now calculated for all regions.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide15.png" alt=""></p>
<ul>
<li><p>4.<strong> Copying/Cleanup Phase:</strong>G1 selects the regions with the lowest “liveness”, those regions which can be collected the fastest. Then those regions are collected at the same time as a young GC. This is denoted in the logs as [GC pause (mixed)]. So both young and old generations are collected at the same time.</p>
</li>
<li><p>5.<strong>After Copying/Cleanup Phase:</strong>The regions selected have been collected and compacted into the dark blue region and the dark green region shown in the diagram.</p>
</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide17.png" alt=""></p>
<ul>
<li><p>6.<strong>Summary of Old Generation GC：</strong></p>
<p>  In summary, there are a few key points we can make about the G1 garbage collection on the old generation：</p>
<p>  <strong>Concurrent Marking Phase</strong></p>
<ul>
<li>Liveness information is calculated concurrently while the application is running.</li>
<li>This liveness information identifies which regions will be best to reclaim during an evacuation pause.</li>
<li><p>There is no sweeping phase like in CMS.</p>
<p><strong>Remark Phase</strong></p>
</li>
<li>Uses the Snapshot-at-the-Beginning (SATB) algorithm which is much faster then what was used with CMS.</li>
<li><p>Completely empty regions are reclaimed.</p>
<p><strong>Copying/Cleanup</strong> </p>
</li>
<li><p>PhaseYoung generation and old generation are reclaimed at the same time.</p>
</li>
<li>Old generation regions are selected based on their liveness.</li>
</ul>
</li>
</ul>
<h3 id="G1相关参数"><a href="#G1相关参数" class="headerlink" title="G1相关参数"></a>G1相关参数</h3><p>-XX:G1HeapRegionSize=n</p>
<pre><code>设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 
Java 堆大小划分出约 2048 个区域。
</code></pre><p>-XX:MaxGCPauseMillis=200</p>
<pre><code>为所需的最长暂停时间设置目标值。默认值是 200 毫秒。指定的值不适用于您的堆大小。
</code></pre><p>-XX:ParallelGCThreads=cpus</p>
<pre><code>设置年轻代垃圾回收(STW)工作线程数的值。将 n 的值设置为逻辑处理器的数量。n 的值
与逻辑处理器的数量相同,G1根据cpu数量设置不同的初始值。
</code></pre><p>-XX:ConcGCThreads=cpus/4</p>
<pre><code>设置并发标记的线程数。将n设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右。
</code></pre><p>-XX:InitiatingHeapOccupancyPercent=45</p>
<pre><code>设置触发标记周期的Java堆占用率阈值。默认占用率是整个 Java 堆的 45%。
</code></pre><p>-XX:G1HeapWastePercent=10</p>
<pre><code>设置G1愿意浪费的堆百分比。如果可回收百分比小于堆废物百分比。默认值是 10%。
</code></pre><p>-XX:G1MixedGCCountTarget=8</p>
<pre><code>设置标记周期完成后，对旧区域执行混合垃圾回收的目标次数。默认值是 8 次混合垃圾回收。
混合回收的目标是控制在此目标次数以内。
</code></pre><p>-XX:G1ReservePercent=10</p>
<pre><code>设置作为空闲空间的预留内存百分比，以降低目标空间溢出的风险。默认值是 10%。增加或
减少百分比时,需要评估Java堆的量。
</code></pre><h3 id="G1优化建议"><a href="#G1优化建议" class="headerlink" title="G1优化建议"></a>G1优化建议</h3><ul>
<li><p>1:不要使用-Xmn/-XX:NewRatio等设置年轻代大小,G1使用逻辑分代,年轻代大小是动态调整的.且固定年轻代的大小会覆盖暂停时间目标</p>
</li>
<li><p>2:暂停时间目标(-XX:MaxGCPauseMillis):设置所需的软实时目标，G1GC 会尽量满足.当对垃圾回收进行评估或调优时,都会涉及到延迟与吞吐量的取舍。需要G1高吞吐量时,暂停时间目标不要太严苛。</p>
</li>
<li><p>3:调优混合垃圾回收时，需合理调整以下参数:<br>-XX:InitiatingHeapOccupancyPercent 用于更改标记阈值。更小的值意味着更快的触发标记周期。<br>-XX:G1MixedGCCountTarget 用于调整Old区域的CSet集合。</p>
</li>
<li><p>4:G1溢出/耗尽引发的FullGc<br>2014-03-06T10:01:28.216+0800: 67998.279: [GC pause (mixed) (to-space exhausted), 13.8681600 secs]<br>2014-03-04T10:01:42.086+0800: 68012.149: [GC pause (mixed) (to-space overflow), 3.0012670 secs]<br>优化参数:<br>增加-XX:G1ReservePercent 选项的值（并相应增加总的堆大小,为”目标空间”预留更多内存空间。<br>减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。<br>增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目,加快标记速度。</p>
</li>
<li><p>5:避免巨型对象<br>G1对于任何超过区域一半大小的对象都被视为“巨型对象”,巨型区域直接被分配到老年代中.<br>巨型区域是一个连续的区域集。StartsHumongous 标记该连续集的开始，ContinuesHumongous 标记它的延续.<br>所以没有使用的巨型对象的终点与上个区域的终点之间的空间无法被使用,<br>如果对象只是略大于堆区域大小的倍数，未使用的空间可能会导致堆碎片化。<br>巨型对象也可能分配导致连续的并发周期，并且此类分配导致老年代碎片化<br>通过增加-XX:G1HeapRegionSize的值,提高巨型对象的门槛(G1HeapRegionSize/2)。</p>
</li>
</ul>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>G1日志分析参考：<a href="https://blogs.oracle.com/poonam/entry/understanding_g1_gc_logs" target="_blank" rel="external">https://blogs.oracle.com/poonam/entry/understanding_g1_gc_logs</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/03/(8.3).JAVA虚拟机(三)-CMS垃圾回收器/" itemprop="url">
                  CMS Heap Stucture
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-08-03T16:37:35+08:00" content="2016-08-03">
              2016-08-03
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JVM</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="概念认知"><a href="#概念认知" class="headerlink" title="概念认知"></a>概念认知</h3><h4 id="枚举根节点-GC-root"><a href="#枚举根节点-GC-root" class="headerlink" title="枚举根节点 GC root"></a>枚举根节点 GC root</h4><p>可达性分析对执行时间的敏感体现在GC停顿上，这项工作分析必须确保能在”一致性”的快照进行操作，(冻结某个时间点上对象引用关系以及任何对象引用变更)，这也是为什么会产生Stop The Word.</p>
<p>在HotSpot虚拟机实现中，是有办法直接获取哪些地方(OopMap的数据结构)存放着对象的引用。当虚拟机在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么数据类型计算出来，再JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是被引用的。</p>
<h4 id="安全点-safe-point"><a href="#安全点-safe-point" class="headerlink" title="安全点 safe point"></a>安全点 safe point</h4><p>在OopMap的协助下，HotSpot可快速且准确的完成GC roots枚举，但是有一个问题：引用关系变化会比较频繁会造成OopMap内容变化指令非常多，那样会需要大量的额外空间，这样GC空间成本会很高。</p>
<p><em>但实际上HotSpot，只是会”特定的位置”记录这些信息，这些位置简称<strong>安全点-safepoint</strong>，即程序执行时并非在所有地方都能停顿下来开始GC，只有达到安全点时才能暂停。</em></p>
<p>如何在GC发生时让所有线程，都”跑”到最近安全点上停顿下来，两种方案：</p>
<ul>
<li>抢断式中断</li>
</ul>
<p>不需要线程的执行代码主动配合，在gc发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，就让”该线程跑到”安全点上。</p>
<ul>
<li>主动式中断 (hotspot)</li>
</ul>
<p>当GC需要中断线程的时候，不需要对线程操作，仅仅简单的设置一个标志位，各个线程执行时 主动去轮训这个标志，发现中断标志位为真，才让线程挂起。</p>
<h4 id="安全区域-safe-region"><a href="#安全区域-safe-region" class="headerlink" title="安全区域 safe region"></a>安全区域 safe region</h4><p>safepoint似乎已经完美解决如何进入GC的问题，但实际情况不一样。safepoint机制是保证程序执行时，在不太久时间内就会遇到可进入GC的safepoint,但是程序 “不执行”的时候呢?</p>
<ul>
<li>程序没有获取到cpu的时间片</li>
<li>线程处于sleep或bolcked状态<br>这些情况线程是无法响应JVM的中断请求，无法”跑到”安全的地方去中断挂起，这里就需要用到 <em>安全区域safe-region</em>来解决。</li>
</ul>
<p><strong>安全区域safe-region</strong>指的是在一段代码片段中，引用关系不会发生变化。在这个区域的任意地方开始GC都是安全的，可以把它看做是safe-point的扩展。</p>
<p>在线程执行到safe Region的代码时，首先标识自己已经进入了Safe Region,那样，当JVM要发起GC时，就不用管标识自己为safe region状态的线程，当线程离开safe region时，就需要检查系统 是否已经完成 根节点枚举，如果完成就继续执行，否则它就必须等待直到收到可以离开safe region的信号为止。</p>
<h4 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h4><p>吞吐量 = 运行用户代码时间/（运行用户代码时间+垃圾收集时间）</p>
<p>虚拟机总共运行100分钟，其中垃圾收集花掉1分钟，那么吞吐量是 99%。</p>
<h4 id="并行-并发收集区别"><a href="#并行-并发收集区别" class="headerlink" title="并行/并发收集区别"></a>并行/并发收集区别</h4><ul>
<li>并行（parallel）：只多条垃圾收集线程并行工作，但此时用户线程任然处于等待状态。</li>
<li>并发(Concurent)：指用户线程与垃圾收集线程同时执行(不一定是并行的，可能需要交替执行)，垃圾收集程序运行另外一个Cpu上。(收集线程数=(cpu数量+3)/4 ,不足4个 对用户程序影响可能变大)</li>
</ul>
<h3 id="Reviewing-Generational-GC-and-CMS"><a href="#Reviewing-Generational-GC-and-CMS" class="headerlink" title="Reviewing Generational GC and CMS"></a>Reviewing Generational GC and CMS</h3><p>The Concurrent Mark Sweep (CMS) collector (also referred to as the concurrent low pause collector) collects the tenured generation. It attempts to minimize the pauses due to garbage collection by doing most of the garbage collection work concurrently with the application threads. Normally the concurrent low pause collector does not copy or compact the live objects. A garbage collection is done without moving the live objects. If fragmentation becomes a problem, allocate a larger heap.  </p>
<p>大致意思：CMS垃圾回收器是回收堆中老年代对象。它与应用线程并行做垃圾回收以减少最小停顿时间，它的最小停顿时间不是因为 复制或整理存活对象，最主要问题是因为碎片化，所以需要分配一个较大的堆。</p>
<p>特点：</p>
<ul>
<li>牺牲吞吐量换取最小停顿时间 </li>
<li>并发标记清除垃圾回收算法</li>
<li>需要一个较大的堆空间</li>
</ul>
<p>问题：</p>
<ul>
<li>产生碎片化</li>
</ul>
<blockquote>
<p>Heap Structure for Cms Collector</p>
</blockquote>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide1.png" alt=""></p>
<h3 id="CMS-Collection-Phase-CMS收集阶段"><a href="#CMS-Collection-Phase-CMS收集阶段" class="headerlink" title="CMS Collection Phase(CMS收集阶段)"></a>CMS Collection Phase(CMS收集阶段)</h3><p>CMS收集器有几个缺点：</p>
<ul>
<li><p>cms收集器占用cpu资源，总吞吐量会降低</p>
<p>  在并发阶段，它虽然不会导致用户线程停顿，但是占用可一部分线程(或者说CPU资源)，从而导致应用程序变慢。</p>
</li>
<li><p>cms收集器无法处理”浮动垃圾”</p>
<p>  由于cms并发清理阶段，用户线程还在运行着，伴随着程序运行自然会产生新的垃圾，这一部分垃圾在标记过程中，无法再这一次GC处理，需要等待下一次GC是再清理掉。这一部分垃圾成为<strong>浮动垃圾</strong>。可以适当调整老年代回收百分比参数：-XX:CMSInitiationgOccupancyFraction ,<strong>还可能会造成Concurrent Mode Failure失败导致另一次FullGC产生。</strong><br>  jdk1.5 老年代触发 百分比68%，JDK1.6 老年代触发百分比 92%</p>
</li>
<li><p>cms收集器会产生空间碎片，可能会造成额外FULL GC触发</p>
<p>  由于CMS是基于”标记-清除”算法实现，意味着收集结束会产生大量空碎片空间，如果碎片过多时，将会给大对象分配带来很大麻烦，此时往往老年代还有很多空间剩余，会造成提前一次进行FULL gc的触发，为解决这个问题，cms提供一个参数 +useCmsCompactAtFullCollection（碎片整理，默认开启），内存整理肯定就增加了停顿时间，虚拟器还提供一个参数-XX:CMSFullGCBeforeCompaction,这个参数 用于设置执行多少次不压缩的Full Gc后，跟着来一次带压缩的(默认值为0，表示每次进入Full GC都要进行碎片整理)</p>
</li>
</ul>
<blockquote>
<p>CMS收集过程</p>
</blockquote>
<p><img src="http://dl2.iteye.com/upload/attachment/0115/7590/5e899581-4025-3895-bc08-d702fc71dff5.png" alt=""></p>
<p>初始标记仅仅是标记一下GC Roots能直接关联到的对象，速度很快，并发标记就是进行<br>GC Roots Trancing的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继<br>续运行而导致标记产生变动那一部分对象的标记记录，这个阶段的停顿时间比初始标记稍<br>长一些，但远比并发标记时间短。</p>
<p><img src="http://i2.itc.cn/20160904/aac_6f45a003_baef_f7c1_93fb_a261e84665e3_1.png" alt=""></p>
<h3 id="How-YoungGC-works-with-GC-CMS年轻代回收过程"><a href="#How-YoungGC-works-with-GC-CMS年轻代回收过程" class="headerlink" title="How YoungGC works with GC(CMS年轻代回收过程)"></a>How YoungGC works with GC(CMS年轻代回收过程)</h3><p>使用算法：copying算法(速度快 存活对象少)</p>
<ul>
<li>1.The young generation is colored light green and the old generation in blue. This is what the CMS might look like if your application has been running for a while. Objects are scattered around the old generation area.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide2.png" alt=""></p>
<ul>
<li>2.Live objects are copied from the Eden space and survivor space to the other survivor space. Any older objects that have reached their aging threshold are promoted to old generation.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide3.png" alt=""></p>
<ul>
<li>3.After a young GC, the Eden space is cleared and one of the survivor spaces is cleared.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide4.png" alt=""><br>Newly promoted objects are shown in dark blue on the diagram. The green objects are surviving young generation objects that have not yet been promoted to old generation. </p>
<h3 id="Old-Generation-Collection-With-CMS（CMS老年代垃圾回收）"><a href="#Old-Generation-Collection-With-CMS（CMS老年代垃圾回收）" class="headerlink" title="Old Generation Collection With CMS（CMS老年代垃圾回收）"></a>Old Generation Collection With CMS（CMS老年代垃圾回收）</h3><ul>
<li>1.Two stop the world events take place: initial mark and remark. When the old generation reaches a certain occupancy rate, the CMS is kicked off。</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide5.png" alt=""><br>(1) Initial mark is a short pause phase where live (reachable) objects are marked. (2) Concurrent marking finds live objects while the application continues to execute. Finally, in the (3) remark phase, objects are found that were missed during (2) concurrent marking in the previous phase.</p>
<ul>
<li>2.Objects that were not marked in the previous phase are deallocated in place. There is no compaction.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide6.png" alt=""><br>Note: Unmarked objects == Dead Objects</p>
<ul>
<li>3.After the (4) Sweeping phase, you can see that a lot of memory has been freed up. You will also notice that no compaction has been done.</li>
</ul>
<p><img src="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/images/slide7.png" alt=""><br>Finally, the CMS collector will move through the (5) resetting phase and wait for the next time the GC threshold is reached..</p>
<h3 id="CMS参数解释"><a href="#CMS参数解释" class="headerlink" title="CMS参数解释"></a>CMS参数解释</h3><p>-XX：+UseConcMarkSweepGC</p>
<pre><code>激活CMS收集器。默认HotSpot JVM使用的是并行收集器
</code></pre><p>-XX：UseParNewGC</p>
<pre><code>当使用-XX：+UseConcMarkSweepGC时，-XX：UseParNewGC会自动开启。因此，
如果年轻代的并行GC不想开启，可以通过设置-XX：-UseParNewGC来关掉。
</code></pre><p>-XX：+CMSConcurrentMTEnabled</p>
<pre><code>当该标志被启用时，并发的CMS阶段将以多线程执行
(因此，多个GC线程会与所有的应用程序线程并行工作)。该标志已经默认开启，
如果顺序执行更好，这取决于所使用的硬件，多线程执行可以通过-XX：-CMSConcurremntMTEnabled禁用。
</code></pre><p>-XX：ConcGCThreads</p>
<pre><code>标志-XX：ConcGCThreads=&lt;value&gt;(早期JVM版本也叫-XX:ParallelCMSThreads)定义并发CMS
过程运行时的线程数。比如value=4意味着CMS周期的所有阶段都以4个线程来执行。尽管更多的线
程会加快并发CMS过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试
来判断增加CMS线程数是否真的能够带来性能的提升。如果还标志未设置，JVM会根据并行收集器中
的-XX：ParallelGCThreads参数的值来计算出默认的并行CMS线程数。该公式是ConcGCThreads
 = (ParallelGCThreads + 3)/4。因此，对于CMS收集器， -XX:ParallelGCThreads标志不
仅影响“stop-the-world”垃圾收集阶段，还影响并发阶段。
</code></pre><p>-XX:CMSInitiatingOccupancyFraction</p>
<pre><code>当堆满之后，并行收集器便开始进行垃圾收集，例如，当没有足够的空间来容纳新分配或提升的对
象,JVM会在一开始执行CMS周期前作一些线索查找。该线索由 -
XX:CMSInitiatingOccupancyFraction=&lt;value&gt;来设置，该值代表老年代堆空间的使用率.
</code></pre><p>-XX：+UseCMSInitiatingOccupancyOnly</p>
<pre><code>触发fullGC的空间百分比，jdk5 默认68%  jdk6 默认92%
</code></pre><p>-XX:+CMSClassUnloadingEnabled</p>
<pre><code>相对于并行收集器，CMS收集器默认不会对永久代进行垃圾回收。如果希望对永久代进行垃圾回收，
可用设置标志-XX:+CMSClassUnloadingEnabled。
</code></pre><p>-XX:+UseCMSCompactAtFullCollection</p>
<pre><code>打开对年老代的压缩.可能会影响性能,但是可以消除碎片,由于并发收集器不对内存空间进行压缩,
整理,所以运行一段时间以后会产生&quot;碎片&quot;,使得运行效率降低.此值设置运行多少次GC以后对内存
空间进行压缩,整理.
</code></pre><p>-XX:+ExplicitGCInvokesConcurrent and </p>
<p>-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses</p>
<p>-XX:+DisableExplicitGC</p>
<p>该标志将告诉JVM完全忽略系统的GC调用(不管使用的收集器是什么类型)</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>oracle官网cms垃圾回收：<a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html" target="_blank" rel="external">http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/02/(8.2).JAVA虚拟机(二)-GC介绍及垃圾回收算法/" itemprop="url">
                  GC介绍及垃圾回收算法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-08-02T16:37:35+08:00" content="2016-08-02">
              2016-08-02
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JVM</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="GC介绍"><a href="#GC介绍" class="headerlink" title="GC介绍"></a>GC介绍</h2><h3 id="什么是GC-Garbage-Collection"><a href="#什么是GC-Garbage-Collection" class="headerlink" title="什么是GC(Garbage Collection)?"></a>什么是GC(Garbage Collection)?</h3><p>垃圾回收器（Garbage Collection，GC）,顾名思义，垃圾回收就是释放垃圾占用的空间， Java中，程序员不需要去关心内存动态分配和垃圾回收的问题，这一切都交给了JVM来处理。<br>我们需要考虑一下JVM处理垃圾回收三个问题：<br>1).哪些内存需要回收？<br>2).GC什么时候开始回收？<br>3).如何回收?</p>
<h3 id="垃圾收集的方式？"><a href="#垃圾收集的方式？" class="headerlink" title="垃圾收集的方式？"></a>垃圾收集的方式？</h3><ul>
<li>引用计数方式</li>
</ul>
<p><img src="http://dl2.iteye.com/upload/attachment/0115/7187/5dcb87dd-84b7-3fd4-990e-4ad03fbb23d3.png" alt=""></p>
<ul>
<li>对象遍历引用方式</li>
</ul>
<p><img src="http://dl2.iteye.com/upload/attachment/0115/7185/d546c4ef-d358-3252-bf83-1cf2a969450d.png" alt=""></p>
          <div class="post-more-link text-center">
            <a class="btn" href="/2016/08/02/(8.2).JAVA虚拟机(二)-GC介绍及垃圾回收算法/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/01/(8.1).JAVA虚拟机(一)-java体系结构及hotspot介绍/" itemprop="url">
                  Java体系结构及内存模型
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-08-01T16:37:35+08:00" content="2016-08-01">
              2016-08-01
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JVM</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="Java概论"><a href="#Java概论" class="headerlink" title="Java概论"></a>Java概论</h2><h3 id="Java体系结构"><a href="#Java体系结构" class="headerlink" title="Java体系结构"></a>Java体系结构</h3><p>java模块划分：</p>
<p><img src="http://i1.itc.cn/20160829/aac_76c29c80_99bc_17d0_839f_c79902930a42_4.png" alt=""></p>
<p>JDK,JRE,JVM,JIT关系:</p>
<p><img src="http://i2.itc.cn/20160829/aac_76c29c80_99bc_17d0_839f_c79902930a42_5.png" alt=""></p>
<h3 id="HotSpot-JVM标准结构"><a href="#HotSpot-JVM标准结构" class="headerlink" title="HotSpot JVM标准结构"></a>HotSpot JVM标准结构</h3><p><img src="http://i3.itc.cn/20160829/aac_76c29c80_99bc_17d0_839f_c79902930a42_1.png" alt=""></p>
<ul>
<li>最上层：javac编译器将编译好的字节码class文件,通过java类装载器的执行机制，把对象或class文件 存放在 jvm划分内存区域</li>
<li>中间层：从左至右 <code>方法区</code>(持久代也叫非堆)、<code>堆</code>(共享,GC回收对象区域)、<code>栈</code>、<code>程序计数器</code>和<code>寄存器</code>、<code>本地栈</code>(私有)</li>
<li>最下层：jvm最核心两块 JIT(just in time)即时编译器 和 GC（Garbage Collection,垃圾回收器）</li>
</ul>
          <div class="post-more-link text-center">
            <a class="btn" href="/2016/08/01/(8.1).JAVA虚拟机(一)-java体系结构及hotspot介绍/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/07/02/(7.4).分布式架构-elasticSearch/" itemprop="url">
                  elasticsearch
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-07-02T10:52:03+08:00" content="2016-07-02">
              2016-07-02
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式/" itemprop="url" rel="index">
                    <span itemprop="name">分布式</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式/搜索引擎/" itemprop="url" rel="index">
                    <span itemprop="name">搜索引擎</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="ElasticSearch初识"><a href="#ElasticSearch初识" class="headerlink" title="ElasticSearch初识"></a>ElasticSearch初识</h2><h3 id="介绍及特点"><a href="#介绍及特点" class="headerlink" title="介绍及特点"></a>介绍及特点</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>作为开源分布式搜索和数据处理平台，Elasticsearch不仅仅是一个数据库，同时它还是一个基于Lucene构建的开源、分布式、RESTful信息检索框架，能够实时搜索，并且稳定可靠，EIK架构为编程人员提供了一个分布式的可扩展的信息检索和基于Lucene的全文搜索，基于Logstash的日志处理机制、基于Kibana的挖掘结果可视化的的机制。</p>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li>分布式实时文件存储</li>
<li>实时分析的分布式搜索引擎</li>
<li>可以扩展到上百台服务器</li>
</ul>
<h4 id="elasticSearch整体架构："><a href="#elasticSearch整体架构：" class="headerlink" title="elasticSearch整体架构："></a>elasticSearch整体架构：</h4><p><img src="http://i1.itc.cn/20160825/aac_540444d4_baf0_549f_ca6b_c9e63308ca75_1.png" alt=""></p>
<!-- more -->
<h4 id="与Lucene的区别？"><a href="#与Lucene的区别？" class="headerlink" title="与Lucene的区别？"></a>与Lucene的区别？</h4><p>Elasticsearch执行搜索的速度更快，可以简单的通过HTTP方式，使用JSON来操作数据，并支持对分布式集群的搜索。<br>Elasticsearch对分布式支持，其索引功能分拆为多个分片，每个分片可有0个或多个副本，集群中的每个数据节点都可承载一个或多个分片，并且能协调和处理各种操作；负载再平衡（Rebalancing）和路由（Routing）在大多数情况下都是自动完成的。</p>
<h3 id="安装及目录"><a href="#安装及目录" class="headerlink" title="安装及目录"></a>安装及目录</h3><blockquote>
<p>安装</p>
</blockquote>
<p><a href="http://www.shaheng.me/blog/2015/06/elasticsearch--.html" target="_blank" rel="external">http://www.shaheng.me/blog/2015/06/elasticsearch--.html</a></p>
<p><a href="http://10.16.51.33:9200/_plugin/head/" target="_blank" rel="external">http://10.16.51.33:9200/_plugin/head/</a></p>
<p>测试路由：<a href="http://10.16.51.33:9200/_plugin/paramedic/index.html" target="_blank" rel="external">http://10.16.51.33:9200/_plugin/paramedic/index.html</a></p>
<blockquote>
<p>源码编译</p>
</blockquote>
<p>jdk1.8/gradle2.8以上版本</p>
<p>gradle compileJava</p>
<blockquote>
<p>data索引目录</p>
</blockquote>
<p><strong>data目录结构：</strong><br><img src="http://i3.itc.cn/20160822/aac_7f64ca29_4b17_68b4_d7eb_26de44fe8832_5.png" alt=""></p>
<pre><code>node.lock    是用来确保一个data目录只被唯一的elasticsearch应用使用。
global_0.st    是个二进制文件，该文件包含了集群的元数据。比如一些persistent持久的修改。
            0表示元数据的版本。
</code></pre><p><strong>index索引目录:</strong><br><img src="http://i0.itc.cn/20160822/aac_7f64ca29_4b17_68b4_d7eb_26de44fe8832_4.png" alt=""></p>
<pre><code>0            表示索引indice2在该节点上的1号分片。
state-23    表示的是索引_state的状态信息，23表示的是版本。这个文件中包含了索引的元数据，                如索引的创建时间，索引的设置和mapping。
state-31    表示的是分片的状态，比如该分片是否是主分片。
</code></pre><h3 id="lucene相关概念"><a href="#lucene相关概念" class="headerlink" title="lucene相关概念"></a>lucene相关概念</h3><blockquote>
<p>index和search过程的流程图</p>
</blockquote>
<p><img src="http://i3.itc.cn/20160825/aac_6527b376_6486_182e_c9e9_096d8163b67d_1.png" alt=""></p>
<pre><code>Lucene的analysis模块主要负责词法分析及语言处理而形成Term。
Lucene的index模块主要负责索引的创建，里面有IndexWriter。
Lucene的store模块主要负责索引的读写。
Lucene的QueryParser主要负责语法分析。
Lucene的search模块主要负责对索引的搜索。
Lucene的similarity模块主要负责对相关性打分的实现。
</code></pre><blockquote>
<p>相关概念</p>
</blockquote>
<p>lucene 存储的层次结构</p>
<p><img src="http://i2.itc.cn/20160825/aac_c36de6c2_193e_b59a_8332_6c7776d106c4_1.png" alt=""></p>
<ul>
<li><p>索引(Index)：在Lucene中一个索引是放在一个文件夹中的。</p>
</li>
<li><p>段(Segment)：一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并。具有相同前缀文件的属同一个段，图中共两个段 “_0” 和 “_1”。<br>segments.gen和segments_5是段的元数据文件，也即它们保存了段的属性信息。</p>
<p>  可参考es： <a href="http://*.*.*.*:9200/kis-index-v1/_segments">http://*.*.*.*:9200/kis-index-v1/_segments</a> 段信息</p>
</li>
<li><p>文档(Document)：<br>文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多篇文档。<br>新添加的文档是单独保存在一个新生成的段中，随着段的合并，不同的文档合并到同一个段中。</p>
</li>
<li><p>域(Field)：一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等，都可以保存在不同的域里。<br>不同域的索引方式可以不同，在真正解析域的存储的时候，我们会详细解读。</p>
</li>
<li><p>词(Term)：<br>词是索引的最小单位，是经过词法分析和语言处理后的字符串。</p>
</li>
</ul>
<p>Lucene的索引结构中，即保存了正向信息，也保存了反向信息。</p>
<blockquote>
<p>elasticsearch保存的部分索引文件格式：</p>
</blockquote>
<p><img src="http://i0.itc.cn/20160822/aac_7f64ca29_4b17_68b4_d7eb_26de44fe8832_3.png" alt="索引文件部分格式"></p>
<p><strong>所谓正向信息：</strong></p>
<p>按层次保存了从索引，一直到词的包含关系：<br>索引(Index) –&gt; 段(segment) (segments.gen, segments_N) -&gt; 文档(Document)–&gt; 域(Field)(fnm, fdx, fdt) –&gt; 词(Term) (tvx, tvd, tvf)<br>也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词。</p>
<p>如上图，包含正向信息的文件有：</p>
<pre><code>segments_N  保存了此索引包含多少个段，每个段包含多少篇文档。
.fnm后缀文件 保存了此段包含了多少个域，每个域的名称及索引方式。
.fdx .fdt后缀文件保存了此段包含的所有文档，每篇文档包含了多少域，每个域保存了那些信息。
.tvx，.tvd，.tvf后缀文件 保存了此段包含多少文档，每篇文档包含了多少域，每个域包含了多少词，每个词的字符串，位置等信息。
</code></pre><p><strong>所谓反向信息：</strong></p>
<p>保存了词典到倒排表的映射：词(Term) –&gt; 文档(Document)</p>
<p>如上图，包含反向信息的文件有：</p>
<pre><code>XXX.tis，XXX.tii保存了词典(Term Dictionary)，也即此段包含的所有的词按字典顺序的排序。
XXX.frq保存了倒排表，也即包含每个词的文档ID列表。
XXX.prx保存了倒排表中每个词在包含此词的文档中的位置。
</code></pre><h3 id="elasticsearch-相关概念"><a href="#elasticsearch-相关概念" class="headerlink" title="elasticsearch 相关概念"></a>elasticsearch 相关概念</h3><p>1).<strong>Cluster和Node</strong>——Elasticsearch中的Cluster是对外提供搜索服务的集群，组成这个集群的各个节点叫Node.集群Cluster是一组有着相同cluster.name的节点，他们协同工作，互相分享数据，提供了故障转移和扩展的功能。Node又分为IndexNode、DataNode等。节点之间是对等关系的(去中心化)，而弱化的Master节点只不过多了维护集群状态的功能。</p>
<p>(2).<strong>Shards</strong>——Elasticsearch将一个完整的索引分成若干个部分，每个部分就是一个Shards，每个Shard实际上就是一个基于Lucene的索引。Shards的数量一般在索引创建前制定，且索引创建后不能更改。</p>
<p>(3).<strong>Replicas</strong>——Replics是索引的冗余备份，可用于防止数据丢失或用来做负载均衡。一般地，Elasticsearch会自动对索引请求进行负载均衡。</p>
<p>(4).<strong>Recover</strong>——在有节点加入或退出集群Cluster或故障节点重新启动时，Elasticsearch会根据机器的负载情况，对索引分片Shards进行重新分配。</p>
<p>(5).<strong>River</strong>——River是一个运行在Elasticsearch集群内部的插件，主要用来从外部获取以后数据，然后在Elasticsearch里创建索引。常见的有MongoDB、JDBC river Plugin等。</p>
<p>(6).<strong>Gateway</strong>——是Elasticsearch索引数据快照的存储方式，当Elasticsearch集群关闭再重新启动时，就会从Gateway中读取索引数据快照。Elasticsearch支持多种类型的Gateway,本地文件系统、分布式文件系统、Hadoop的HDFS</p>
<p>(7).<strong>Discover.zen</strong>——Discover.zen代表Elasticsearch的自动发现节点机制。Zen用来实现节点自动发现和Master节点选举，Master节点负责节点的加入和退出以及分片shard的重新分配。</p>
<p>(8).<strong>Transport</strong>——Transport代表Elasticsearch内部节点或集群与客户端的交互方式，默认内部是使用TCP协议进行交互的，同时支持HTTP协议(JSON格式)、Thrift、Servlet等传输协议。</p>
<p>(9)<strong>Index、Type、Document、Field</strong>——Index是数据存储的地方，可以快速高效的堆索引中的数据进行全文索引，类似于RDBMS数据库中的Database;在Index下一般会有多个存储数据的Type,Type类似于Database的table,用来存放具体数据；Document类似于关系数据库的一行数据，在一个Type里的每一个Document都有一个唯一的ID作为区分。</p>
<p>(10)<strong>Mapping</strong>——Mapping定义索引下的Type的字段处理规则，如索引如何建立、索引数据类型、是否保存原始索引JSON文档，是否需要进行分词处理、如何进行分词处理等。一般地，一个索引文件下能存储不同映像(Mapping)的类型文件(Types).</p>
<p>RESTful接口URL的格式：</p>
<pre><code>curl -X&lt;VERB&gt; &apos;&lt;PROTOCOL&gt;://&lt;HOST&gt;/&lt;PATH&gt;?&lt;QUERY_STRING&gt;&apos; -d &apos;&lt;BODY&gt;&apos;

VERB HTTP方法：GET(获取), POST(更新), PUT(创建), HEAD, DELETE(删除)
PROTOCOL： http或者https协议（只有在Elasticsearch前面有https代理的时候可用）
HOST： Elasticsearch集群中的任何一个节点的主机名，如果是在本地的节点，那么就叫localhost
PORT： Elasticsearch HTTP服务所在的端口，默认为9200
QUERY_STRING： 一些可选的查询请求参数，例如?pretty参数将使请求返回更加美观易读的JSON数据
BODY： 一个JSON格式的请求主体（如果请求需要的话）
</code></pre><h2 id="ElasticSearch存储结构"><a href="#ElasticSearch存储结构" class="headerlink" title="ElasticSearch存储结构"></a>ElasticSearch存储结构</h2><h3 id="lucene文件存储格式"><a href="#lucene文件存储格式" class="headerlink" title="lucene文件存储格式"></a>lucene文件存储格式</h3><p><img src="http://i2.itc.cn/20160822/aac_7f64ca29_4b17_68b4_d7eb_26de44fe8832_2.png" alt=""><br><img src="http://i1.itc.cn/20160822/aac_7f64ca29_4b17_68b4_d7eb_26de44fe8832_1.png" alt=""></p>
<p><strong>fdx和fdt的结构:</strong></p>
<p>对于每一个域，fieldnum是域号，接着是一个8位的byte，最低一位表示此域是否分词(tokenized)，倒数第二位表示此域是保存字符串数据还是二进制数据，倒数第三位表示此域是否被压缩，再接下来就是存储域的值。</p>
<p>类似 B+树的数据结构：<br><img src="http://i0.itc.cn/20160822/aac_e565d05b_1515_9665_2783_3397228cde23_3.png" alt=""></p>
<p>文件存储大小：<br><img src="http://i2.itc.cn/20160822/aac_5d8cc8be_6498_ec9e_1234_807d0f00ce71_1.png" alt=""></p>
<h3 id="ElasticSearch存储模块"><a href="#ElasticSearch存储模块" class="headerlink" title="ElasticSearch存储模块"></a>ElasticSearch存储模块</h3><ul>
<li><p>simple fs(简单文件系统存储)：对应Lucene中的SimpleFsDirectory。 这种实现的并发性能较差，<strong>多线程会出现瓶颈</strong>。当索引需要持久化最好使用niofs。【windows 32位系统默认使用存储类型】</p>
</li>
<li><p>nio fs(新I/O文件系统存储)：对应Lucene中的NIOFSDirectory。这种方式可以<strong>多个线程在不降低性能的前提下并发地读同一个文件</strong>。【除开simple fs和mmmapfs以外  默认使用存储类型】</p>
</li>
<li><p>mmapfs：它使用mmap系统命令来读取和随机写入文件，并从进程的虚拟地址空间的可用部分中分出与被映射文件大小相同的空间没用于装载被映射文件。它<strong>没有任何锁机制，适合多线程访问，当时有mmap来读取索引时 他就像已经缓存过(映射到虚拟地址空间)，当从lucene索引读取某文件时，不需要把文件载入操作系统缓存中，因此获得了更快的访问速度。这基本上允许lucene和elasticsearch去直接访问I/O缓存，从而获得更快的索引文件访问速度。 一般来说，如果运行的是64位操作系统，你应该选择mmapfs。如果没有运行64位操作系统，为UNIX系统选择niofs，为Windows系统选择simplefs。</strong>【Solaris和windows 64位系统使用存储类型】</p>
</li>
<li><p>memory：对应Lucene中的RamIndexStore，它允许我们把全部索引存放在内存中，因此文件没有存储在硬盘上。这意味着 索引数据是非持久化的，只要集群重启 数据就会被丢失。</p>
</li>
</ul>
<blockquote>
<p>配置</p>
</blockquote>
<pre><code>设置存储类型 index.store.type:

线上es配置：
index.translog.flush_threshold_period: 600s
index.refresh_interval: 10s
indices.memory.index_buffer_size: 30%
indices.memory.min_index_buffer_size: 500m
index.translog.flush_threshold: 50000
index.store.type: mmapfs
index.merge.policy.use_compound_file: false
index.cache.field.type: soft
</code></pre><h3 id="store-level-throttling"><a href="#store-level-throttling" class="headerlink" title="store level throttling"></a>store level throttling</h3><p>Elasticsearch中的segments merge采用异步的方式，但系统低IO的情况下还是会影响索引和查询操作。想要解决这种问题，Elasticsearch提供两种方式（索引级别和节点 级别）的配置。</p>
<pre><code>节点级别配置：
    indices.store.throttle.type：merge
    indices.store.throttle.max_bytes_per_sec：5mb //默认20mb 如上设置之后，该节点上的segments merge不会超过5mb/s
索引级别设置：
    index.store.throttle.type：node
    index.store.throttle.max_bytes_per_sec：10mb
</code></pre><h3 id="段合并策略"><a href="#段合并策略" class="headerlink" title="段合并策略"></a>段合并策略</h3><p>段合并直接影响到系统的性能，需要进行大量的IO操作。段合并策略如下：</p>
<ul>
<li>tiered(默认)</li>
</ul>
<p>ElasticSearch默认合并策略，它能合并大小相似的索引段，并考虑每层允许的索引段的最大个数。</p>
<ul>
<li>log_byte_size</li>
</ul>
<p>按字节数 进行合并</p>
<ul>
<li>log_doc</li>
</ul>
<p>按段里存储doc进行合并</p>
<ul>
<li><p>参数配置</p>
<pre><code>index.merge.policy.type:tiered
</code></pre></li>
</ul>
<blockquote>
<p>segment结构</p>
</blockquote>
<p><img src="http://i2.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_5.png" alt=""><br><img src="http://i0.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_1.png" alt=""><br><img src="http://i1.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_6.png" alt=""><br><img src="http://i3.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_7.png" alt=""><br><img src="http://i1.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_8.png" alt=""></p>
<blockquote>
<p>合并过程</p>
</blockquote>
<ul>
<li>提交过程</li>
</ul>
<p><img src="http://i3.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_4.png" alt=""></p>
<ul>
<li>数据落地的步骤</li>
</ul>
<p><img src="http://i0.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_3.png" alt=""></p>
<ul>
<li>segment合并的过程:</li>
</ul>
<p><img src="http://i1.itc.cn/20160825/aac_82ddb3fc_de8e_67c7_9a85_19b3df5f55e7_2.png" alt=""></p>
<h3 id="准实时、更新、提交及事务日志"><a href="#准实时、更新、提交及事务日志" class="headerlink" title="准实时、更新、提交及事务日志"></a>准实时、更新、提交及事务日志</h3><p>一个好的搜索引擎需要保证在新索引建立后 数据如何能够立即检索到，</p>
<blockquote>
<p>准实时-版本_version</p>
</blockquote>
<pre><code>每次新建索引 会产生一个新的文档，_version+1，标记旧文档为删除并添加了一个完整的新文
档,旧版本文档不会立即消失，但你也不能去访问它。Elasticsearch会在你继续索引更多数据时
清理被删除的文档。如果新的未建成功，访问仍然是旧的文档内容。
</code></pre><p><img src="http://i3.itc.cn/20160825/aac_ff5c6654_3690_2fab_bb7b_439b305b5141_1.png" alt=""> </p>
<blockquote>
<p>索引更新/提交涉及段的合并</p>
</blockquote>
<p>事实上Elasticsearch遵循与之前所说完全相同的过程，这个过程如下：</p>
<ul>
<li>从旧文档中检索JSON</li>
<li>修改它</li>
<li>删除旧文档</li>
<li>索引新文档</li>
</ul>
<p>唯一的不同是update API完成这一过程只需要一个客户端请求既可，不再需要get和index请求了.    </p>
<pre><code>_refresh索引刷新:

    设置参数  &quot;refresh_interval&quot;:&quot;10s/m/h(时间单位)&quot;
    curl -XGET &apos;http://10.16.51.33:9200/data-test/_refresh&apos;
</code></pre><blockquote>
<p>事务日志刷新</p>
</blockquote>
<pre><code>_flush日志刷新：

    设置参数 
    curl -XGET &apos;http://10.16.51.33:9200/data-test/_flush&apos;
    {&quot;_shards&quot;:{&quot;total&quot;:10,&quot;successful&quot;:10,&quot;failed&quot;:0}}
</code></pre><p>查看数据分片情况：<br><img src="http://i1.itc.cn/20160825/aac_ff5c6654_3690_2fab_bb7b_439b305b5141_2.png" alt=""><br>执行flush之后<br><img src="http://i1.itc.cn/20160825/aac_ff5c6654_3690_2fab_bb7b_439b305b5141_3.png" alt=""></p>
<h2 id="ElasticSearch分布式集群"><a href="#ElasticSearch分布式集群" class="headerlink" title="ElasticSearch分布式集群"></a>ElasticSearch分布式集群</h2><p>es官方文档讲解cluster：<br><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/distributed-cluster.html" target="_blank" rel="external">https://www.elastic.co/guide/en/elasticsearch/guide/current/distributed-cluster.html</a></p>
<p>集群健康：<a href="http://10.16.51.33:9200/_cluster/health" target="_blank" rel="external">http://10.16.51.33:9200/_cluster/health</a></p>
<h3 id="通信机制-发现模块"><a href="#通信机制-发现模块" class="headerlink" title="通信机制-发现模块"></a>通信机制-发现模块</h3><p>该模块主要负责集群中节点的自动发现和Master节点的选举。节点之间使用p2p的方式进行直接通信，不存在单点故障的问题。Elasticsearch中，Master节点维护集群的全局状态，比如节点加入和离开时进行shard的重新分配。通过发现机制(discovery mechanism)极大简化了 集群工作，只需要定义了相同的cluster.name的节点会自动组成集群，需要在同一个网段。</p>
<ul>
<li><p>zen discovery elasticSearch默认实现 多播/单播</p>
<p>  <strong>Master选举</strong>：设置最小主节点候选节点数应设置 集群节点数一半+1，通过参数 discovery.zen.minimum_master_nodes配置当前集群中最少的主节点数。</p>
<p>  <strong>Zen错误发现</strong>：一般存在两个故障检测过程。</p>
<pre><code>第一个是主节点周期性的ping其他节点。
第二就是其他节点周期的ping主节点。
</code></pre><p>  ping_interval：1s节点被ping的频率<br>  ping_timeout：30s等待ping返回的时间<br>  ping_timeout：3重试次数，超过该次，就认为该节点不可用  </p>
<p>  参数配置</p>
<p>  多播：<br>  discovery.zen.ping.multicast.group: 代表发送多播消息地址，默认 224.2.2.4<br>  discovery.zen.ping.multicast.port： 通讯端口，默认值：54328<br>  discovery.zen.ping.multicast.ttl:   定义多播消息的生存期，默认是3<br>  discovery.zen.ping.multicast.address:通讯接口，可赋值地址或接口，默认值：所有接口<br>  discovery.zen.ping.multicast.enabled: 多播自动发现禁用开关 默认值：true</p>
<p>  单播：<br>  discovery.zen.ping.unicast.hosts:host1：port1，host2,：port2  </p>
</li>
<li><p>Azure discovery 插件方式，多播</p>
</li>
<li>EC2 discovery 插件方式，多播</li>
<li>Google Compute Engine (GCE)discovery 插件方式多播</li>
</ul>
<h3 id="故障转移-failover"><a href="#故障转移-failover" class="headerlink" title="故障转移 failover"></a>故障转移 failover</h3><p>数据迁移规则？ 主节点 竞选规则    裁决者</p>
<h3 id="水平-垂直扩容-scale-Horizontally"><a href="#水平-垂直扩容-scale-Horizontally" class="headerlink" title="水平/垂直扩容 scale Horizontally"></a>水平/垂直扩容 scale Horizontally</h3><h3 id="ElasticSearch工作流程"><a href="#ElasticSearch工作流程" class="headerlink" title="ElasticSearch工作流程"></a>ElasticSearch工作流程</h3><blockquote>
<p>创建、索引和删除文档</p>
</blockquote>
<p><img src="http://i1.itc.cn/20160824/aac_058a4586_c0ec_cfc4_ffba_eb1a858f787e_5.png" alt=""></p>
<pre><code>该过程分为以下3步：
1.客户端发送一个创建、检索或删除文档的请求到节点1。
2.节点使用文档的_id（默认情况下，即不指定路由）判断该文档属于分片0。转发请求到主分片0所在的节点3上。
3.节点3在主分片上执行请求。如果成功，则并行的发送请求到0分片的副本分片所在的节点1和节点2上。当所有的副本分片执行成功后，节点3向请求节点报告操作成功，最后请求节点向客户端报告成功。

可以通过修改可选请求参数去修改上述过程。
replication：（默认sync）
    sync：主分片会等待从分片执行成功，然后返回给客户端。
    async：当主分片执行成功则返回给客户端。
    With async replication, it is possible to overload Elasticsearch by sending too many requests without waiting for their completion.

consistency和timeout：
quorum（法定人数）=int( (primary + number_of_replicas) / 2 ) + 1 
只有当活跃的节点数&gt;=quorum时，对索引的创建，索引和删除才会成功。否则等待timeout时长，默认为1分钟，如果期间节点恢复运行，则可以执行索引的创建，索引和删除。否则失败。但是对索引的查询没有影响。
但是当number_of_replicas=1的时候，则无上述限制，即使只有一个节点的时候，也可以进行索引的创建，索引和删除操作。
</code></pre><blockquote>
<p>检索文档</p>
</blockquote>
<p><img src="http://i3.itc.cn/20160824/aac_058a4586_c0ec_cfc4_ffba_eb1a858f787e_3.png" alt=""></p>
<pre><code>该过程分为以下3个部分：
1.客户端发送请求到节点1
2.节点使用_id判断文档属于分片0，分片0存在于这3个节点上。在这个例子中该请求会转发到节点2上。
3.节点2返回文档到节点1，然后节点1再将文档返回客户端。
注：在第二步中之所以要将请求转发到节点2，是为了负载均衡，当节点收到检索命令的时候，elasticsearch会轮询文档所在的分片。
</code></pre><blockquote>
<p>更新文档</p>
</blockquote>
<p><img src="http://i3.itc.cn/20160824/aac_058a4586_c0ec_cfc4_ffba_eb1a858f787e_2.png" alt=""></p>
<pre><code>该过程分为以下4个部分：
1.客户端发送请求到节点1。
2.转发请求到文档所在的主节点3上。
3.节点3从主分片中检索到文档，然后改变文档_source的json数据，尝试重新索引到主分片，如果在这个过程中该文档已经被其他的进程修改了，那么会重复步骤3，如果经过retry_on_conflict 次尝试还是失败，则放弃更新。
4.如果节点3成功的更新了文档，它会将新的文档并行的发送到副本分片所在的节点1和2上。当所有的副本分片都成功的创建了文档时，节点3会通知请求节点更新成功，请求节点再通知客户端更新成功。
注：当主分片转发变更到它的副本分片的时候，它不会发送更新请求，而是发送新版本的文档。
</code></pre><blockquote>
<p>mget操作</p>
</blockquote>
<p><img src="http://i3.itc.cn/20160824/aac_058a4586_c0ec_cfc4_ffba_eb1a858f787e_2.png" alt=""></p>
<pre><code>该过程分为以下两步：
1.客户端发送mget请求到节点1。
2.节点1为每个分片建立一个multi-get请求，并行的发送这些请求到分片所在的主节点或从节点上。当所有分片的响应被返回到节点1时，节点1会建立响应并发送回客户端。
</code></pre><blockquote>
<p>bulk操作</p>
</blockquote>
<p><img src="http://i3.itc.cn/20160824/aac_058a4586_c0ec_cfc4_ffba_eb1a858f787e_1.png" alt=""></p>
<pre><code>该过程步骤如下：
1.客户端发送bulk请求到节点1。
2.节点1为每个主分片建立一个bulk请求，并行的发送这些请求到主分片所在的节点上。
3.主节点顺序的执行每个action，当每一个action成功后，主分片会并行的发送新的文档到副本分片上，然后主分片继续下一个action，当所有副本分片对于所有action的命令都成功时，会向请求节点报告成功，然后请求节点会整理这些响应，并返回到客户端。
注：这个bulk请求需要被读入到内存中，所以越大的请求意味着能被其他请求使用的内存越小。一般来说，bulk请求包含1000-5000个文档，如果文档越大则bulk包含的文档越少。一个好的bulk的size应该在5-15MB左右。
</code></pre><blockquote>
<p>msearch操作/sort排序</p>
</blockquote>
<h3 id="路由模块"><a href="#路由模块" class="headerlink" title="路由模块"></a>路由模块</h3><p>索引别名相当于快捷方式或软链接，可以指向一个或多个索引，甚至可以指向带路由的分片。</p>
<p>指定路由 ：</p>
<p>查询路由：</p>
<p>curl -XGET ‘<a href="http://10.16.51.33:9200/kis-index-v1/kisstar/_search?query=starName:ladygaga&amp;routing=2&amp;explain&amp;pretty" target="_blank" rel="external">http://10.16.51.33:9200/kis-index-v1/kisstar/_search?query=starName:ladygaga&amp;routing=2&amp;explain&amp;pretty</a>‘</p>
<ul>
<li><p>应用实例</p>
<p>  1.将某一聚类数据 特意放在某一分片，提高检索效率</p>
<pre><code>1.1 将用户的数据集放到一个分片
1.2 将专辑下的视频放到一个分片
</code></pre></li>
</ul>
<h3 id="索引别名模块"><a href="#索引别名模块" class="headerlink" title="索引别名模块"></a>索引别名模块</h3><p>Elasticsearch的API支持给索引起别名，有了别名之后可以像使用索引一样使用它。但不只是这些，一个别名可以映射多个索引，所以在需要经常指定多个索引查询的情况下，大可将所查询的索引起一个别名来查。别名也可以将索引查询的过滤条件包含在内，使用别名查询时可以查询索引的一个子集。</p>
<ul>
<li><p>创建一个别名：</p>
<p>  curl -XPOST ‘<a href="http://localhost:9200/_aliases&#39;-d" target="_blank" rel="external">http://localhost:9200/_aliases&#39;-d</a> ‘<br>  {  </p>
<pre><code>&quot;actions&quot; : [  
    { &quot;add&quot; : { &quot;index&quot; : &quot;test1&quot;,&quot;alias&quot; : &quot;alias1&quot; } }  
]  
</code></pre><p>  }’  </p>
</li>
<li><p>删除别名：</p>
<p>  curl -XPOST ‘<a href="http://localhost:9200/_aliases&#39;-d" target="_blank" rel="external">http://localhost:9200/_aliases&#39;-d</a> ‘<br>  {  </p>
<pre><code>&quot;actions&quot; : [  
    { &quot;remove&quot; : { &quot;index&quot; : &quot;test1&quot;,&quot;alias&quot; : &quot;alias1&quot; } }  
]  
</code></pre><p>  }’ </p>
</li>
</ul>
<h2 id="ElasticSearch原理使用"><a href="#ElasticSearch原理使用" class="headerlink" title="ElasticSearch原理使用"></a>ElasticSearch原理使用</h2><h3 id="文档存储及映射规则"><a href="#文档存储及映射规则" class="headerlink" title="文档存储及映射规则"></a>文档存储及映射规则</h3><h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><p>java主类位于org.elasticsearch.bootstrap。主要逻辑是生成了一个InternalNode节点，并且启动了一个keepalive线程。结点的启动代表整个es进程启动了。</p>
<p>Bootstarp启动线程 Node Keepalive</p>
<p>client  TransportClient</p>
<p>~~<br>public enum SearchType {<br>        /**</p>
<pre><code> * Same as {@link #QUERY_THEN_FETCH}, except for an initial scatter phase which goes and computes the distributed
 * term frequencies for more accurate scoring.
 */
DFS_QUERY_THEN_FETCH((byte) 0),
/**
 * The query is executed against all shards, but only enough information is returned (not the document content).
 * The results are then sorted and ranked, and based on it, only the relevant shards are asked for the actual
 * document content. The return number of hits is exactly as specified in size, since they are the only ones that
 * are fetched. This is very handy when the index has a lot of shards (not replicas, shard id groups).
 */
QUERY_THEN_FETCH((byte) 1),
/**
 * Same as {@link #QUERY_AND_FETCH}, except for an initial scatter phase which goes and computes the distributed
 * term frequencies for more accurate scoring.
 */
DFS_QUERY_AND_FETCH((byte) 2),
/**
 * The most naive (and possibly fastest) implementation is to simply execute the query on all relevant shards
 * and return the results. Each shard returns size results. Since each shard already returns size hits, this
 * type actually returns size times number of shards results back to the caller.
 */
QUERY_AND_FETCH((byte) 3),
/**
 * Performs scanning of the results which executes the search without any sorting.
 * It will automatically start scrolling the result set.
 */
SCAN((byte) 4),
/**
 * Only counts the results, will still execute facets and the like.
 */
COUNT((byte) 5);

/**
 * The default search type ({@link #QUERY_THEN_FETCH}.
 */
public static final SearchType DEFAULT = QUERY_THEN_FETCH;
</code></pre><ul>
<li>query and fetch</li>
</ul>
<p>向索引的所有分片（shard）都发出查询请求，各分片返回的时候把元素文档（document）和计算后的排名信息一起返回。这种搜索方式是最快的。因为相比下面的几种搜索方式，这种查询方法只需要去shard查询一次。但是各个shard返回的结果的数量之和可能是用户要求的size的n倍。</p>
<ul>
<li>query then fetch（默认的搜索方式）</li>
</ul>
<p>如果你搜索时，没有指定搜索方式，就是使用的这种搜索方式。这种搜索方式，大概分两个步骤，第一步，先向所有的shard发出请求，各分片只返回排序和排名相关的信息（注意，不包括文档document)，然后按照各分片返回的分数进行重新排序和排名，取前size个文档。然后进行第二步，去相关的shard取document。这种方式返回的document与用户要求的size是相等的。</p>
<ul>
<li>DFS query and fetch</li>
</ul>
<p>这种方式比第一种方式多了一个初始化散发(initial scatter)步骤，有这一步，据说可以更精确控制搜索打分和排名。</p>
<ul>
<li>DFS query then fetch</li>
</ul>
<p>比第2种方式多了一个初始化散发(initial scatter)步骤。</p>
<h3 id="API使用"><a href="#API使用" class="headerlink" title="API使用"></a>API使用</h3><blockquote>
<p>文档存储机制</p>
<p>文档CRUD</p>
</blockquote>
<p>PUT/POST/GET/DELETE </p>
<ul>
<li><p>Manually (aka do it yourself) using native byte[] or as a String</p>
<pre><code>String json = &quot;{&quot; +
    &quot;\&quot;user\&quot;:\&quot;kimchy\&quot;,&quot; +
    &quot;\&quot;postDate\&quot;:\&quot;2013-01-30\&quot;,&quot; +
    &quot;\&quot;message\&quot;:\&quot;trying out Elasticsearch\&quot;&quot; +
&quot;}&quot;;
</code></pre></li>
<li><p>Using a Map that will be automatically converted to its JSON equivalent</p>
<pre><code>Map&lt;String, Object&gt; json = new HashMap&lt;String, Object&gt;();
json.put(&quot;user&quot;,&quot;kimchy&quot;);
json.put(&quot;postDate&quot;,new Date());
json.put(&quot;message&quot;,&quot;trying out Elasticsearch&quot;);
</code></pre></li>
<li><p>Using a third party library to serialize your beans such as Jackson</p>
<pre><code>// instance a json mapper
ObjectMapper mapper = new ObjectMapper(); // create once, reuse

// generate json
byte[] json = mapper.writeValueAsBytes(yourbeaninstance);
</code></pre></li>
<li><p>Using built-in helpers XContentFactory.jsonBuilder()</p>
<pre><code>XContentBuilder builder = jsonBuilder()
.startObject()
    .field(&quot;user&quot;, &quot;kimchy&quot;)
    .field(&quot;postDate&quot;, new Date())
    .field(&quot;message&quot;, &quot;trying out Elasticsearch&quot;)
.endObject();
String json = builder.string();
</code></pre></li>
</ul>
<blockquote>
<p>批量机制 mget bulk msearch </p>
<p>排序规则</p>
</blockquote>
<h2 id="ElasticSearch客户端使用"><a href="#ElasticSearch客户端使用" class="headerlink" title="ElasticSearch客户端使用"></a>ElasticSearch客户端使用</h2><h3 id="maven依赖"><a href="#maven依赖" class="headerlink" title="maven依赖"></a>maven依赖</h3><p>maven中央仓库：<a href="http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22org.elasticsearch%22%20AND%20a%3A%22elasticsearch%22" target="_blank" rel="external">http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22org.elasticsearch%22%20AND%20a%3A%22elasticsearch%22</a></p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;
    &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;
    &lt;version&gt;${es.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><h3 id="客户端TransportClient实例化"><a href="#客户端TransportClient实例化" class="headerlink" title="客户端TransportClient实例化"></a>客户端TransportClient实例化</h3><p>Obtaining an elasticsearch Client is simple. The most common way to get a client is by creating a TransportClient that connects to a cluster.</p>
<blockquote>
<p>获取es的client</p>
</blockquote>
<pre><code>// on startup
Client client = TransportClient.builder().build()
        .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(&quot;host1&quot;), 9300))
        .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(&quot;host2&quot;), 9300));

// on shutdown
client.close();

// 设置es的别名，否则名称命名为&quot;elasticsearch&quot;
Settings settings = Settings.settingsBuilder()
    .put(&quot;cluster.name&quot;, &quot;myClusterName&quot;).build();
Client client = TransportClient.builder().settings(settings).build();
//Add transport addresses and do something with the client...

// 设置sniff为true 能自动嗅探 host变更
Settings settings = Settings.settingsBuilder()
    .put(&quot;client.transport.sniff&quot;, true).build();
TransportClient client = TransportClient.builder().settings(settings).build();
</code></pre><blockquote>
<p>工厂类封装es客户端</p>
</blockquote>
<pre><code>//    1.es api接口实现类
public class ElasticSearchCenterImpl implements ElasticSearchCenter {
    private final Logger logger = LoggerFactory.getLogger(this.getClass());
    private Client client = ElasticSearchClientFactory.createTransportClient();
    //封装es api 接口实现，通过client调用
}

// 2.es api接口定义
public interface ElasticSearchCenter {
    // 定义es api 接口方法
}

// 3.封装TransportClient工厂类 通过配置文件进行初始化
public class ElasticSearchClientFactory {
    private static volatile Client client;

    private ElasticSearchClientFactory() {
    }
    /**
     * create a transport client
     *
     * @return
     */
    public static Client createTransportClient() {
        if (client == null) {
            synchronized (Client.class) {
                if (client != null) {
                    return client;
                }
                ResourceBundle resourceBundle = ResourceBundle.getBundle(&quot;index-engine&quot;);
                String clusterName = resourceBundle.getString(&quot;es.cluster.name&quot;);
                String timeout = resourceBundle.getString(&quot;es.client.transport.ping_timeout&quot;);
                String hosts = resourceBundle.getString(&quot;es.hosts&quot;);
                String sniff = resourceBundle.getString(&quot;es.client.transport.sniff&quot;);

                Settings settings = ImmutableSettings.settingsBuilder()
                        .put(&quot;client.transport.sniff&quot;, sniff)
                        .put(&quot;cluster.name&quot;, clusterName)
                        .put(&quot;client.transport.ping_timeout&quot;, timeout)
                        .build();
                TransportClient innerClient = new TransportClient(settings);
                String[] hostPorts = hosts.split(&quot;,&quot;);
                for (String hostPort : hostPorts) {
                    String[] array = hostPort.split(&quot;:&quot;);
                    innerClient.addTransportAddress(new InetSocketTransportAddress(array[0], Integer.parseInt(array[1])));
                }
                client = innerClient;
            }
        }
        return client;
    }
}
</code></pre><blockquote>
<p>spring启动初始化工厂类</p>
</blockquote>
<pre><code>// 1.添加配置文件
es.hosts=ip:host,ip2:host2,ip3:host3,ip4:host4
es.cluster.name=es-engine-online
es.client.transport.ping_timeout=15000
es.client.transport.sniff=true
// 2.添加spring配置
&lt;!-- elasticsearch  --&gt;
&lt;bean id=&quot;elasticSearchCenter&quot; class=&quot;com.sohu.tv.index.data.engine.es.impl.ElasticSearchCenterImpl&quot; /&gt;
</code></pre><h2 id="ElasticSearch故障处理"><a href="#ElasticSearch故障处理" class="headerlink" title="ElasticSearch故障处理"></a>ElasticSearch故障处理</h2><h3 id="垃圾回收器工作情况"><a href="#垃圾回收器工作情况" class="headerlink" title="垃圾回收器工作情况"></a>垃圾回收器工作情况</h3><h3 id="IO调节"><a href="#IO调节" class="headerlink" title="IO调节"></a>IO调节</h3><h3 id="预热器的使用"><a href="#预热器的使用" class="headerlink" title="预热器的使用"></a>预热器的使用</h3><h3 id="热点线程分析"><a href="#热点线程分析" class="headerlink" title="热点线程分析"></a>热点线程分析</h3><p>热点线程：<a href="http://10.16.51.33:9200/_nodes/hot_threads?type=wait&amp;interval=1s" target="_blank" rel="external">http://10.16.51.33:9200/_nodes/hot_threads?type=wait&amp;interval=1s</a></p>
<h3 id="诊断集群和节点故障API"><a href="#诊断集群和节点故障API" class="headerlink" title="诊断集群和节点故障API"></a>诊断集群和节点故障API</h3><h2 id="Elasticsearch运维使用"><a href="#Elasticsearch运维使用" class="headerlink" title="Elasticsearch运维使用"></a>Elasticsearch运维使用</h2><h3 id="运维命令"><a href="#运维命令" class="headerlink" title="运维命令"></a>运维命令</h3><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><pre><code>ElasticSearch 官方文档 ： https://www.elastic.co/guide/index.html
Elasticsearch 权威指南（中文版）：http://es.xiaoleilu.com/
Elasticsearch资料 : http://blog.csdn.net/july_2/article/details/24453903
ElasticsSearch博客：http://blog.csdn.net/changong28/article/category/2381639/2    

lucene基本概念：http://forfuture1978.iteye.com/blog/546771
lucene文件格式解析：
http://www.cnblogs.com/forfuture1978/archive/2009/12/14/1623597.html
http://www.cnblogs.com/forfuture1978/archive/2009/12/14/1623599.html
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/07/01/(7.1).分布式架构-dubbo/" itemprop="url">
                  dubbo架构和源码分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-07-01T10:52:03+08:00" content="2016-07-01">
              2016-07-01
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式/" itemprop="url" rel="index">
                    <span itemprop="name">分布式</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="dubbo架构原理"><a href="#dubbo架构原理" class="headerlink" title="dubbo架构原理"></a>dubbo架构原理</h2><blockquote>
<h3 id="框架设计"><a href="#框架设计" class="headerlink" title="框架设计"></a>框架设计</h3></blockquote>
<p><img src="http://i2.itc.cn/20160517/aac_f5d59df3_6197_4d8e_0bd9_908362449c02_2.png" alt="dubbo框架结构"></p>
<ul>
<li><code>config，配置层</code>，对外配置接口，以ServiceConfig, ReferenceConfig为中心，可以直接new配置类，也可以通过spring解析配置生成配置类</li>
<li><code>proxy，服务代理层</code>，服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory</li>
<li><code>registry，注册中心层</code>，封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory, Registry, RegistryService</li>
<li><code>cluster，路由层</code>，封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster, Directory, Router, LoadBalance</li>
<li><code>monitor，监控层</code>，RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory, Monitor, MonitorService</li>
<li><code>protocol，远程调用层</code>，封将RPC调用，以Invocation, Result为中心，扩展接口为Protocol, Invoker, Exporter</li>
<li><code>exchange，信息交换层</code>，封装请求响应模式，同步转异步，以Request, Response为中心，扩展接口为Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer</li>
<li><code>transport，网络传输层</code>，抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel, Transporter, Client, Server, Codec</li>
<li><code>serialize，数据序列化层</code>，可复用的一些工具，扩展接口为Serialization, ObjectInput, ObjectOutput, ThreadPool</li>
</ul>
<blockquote>
<h3 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h3></blockquote>
<p><img src="http://i3.itc.cn/20160516/aac_ec527bd3_be4b_a20b_eb92_3020fcd4d4f7_4.jpg" alt="dubbo服务端和客户端调用关系"></p>
<p><strong>节点角色说明：</strong></p>
<ul>
<li>Provider: 暴露服务的服务提供方。</li>
<li>Consumer: 调用远程服务的服务消费方。</li>
<li>Registry: 服务注册与发现的注册中心。</li>
<li>Monitor: 统计服务的调用次调和调用时间的监控中心。</li>
<li>Container: 服务运行容器。</li>
</ul>
<p><strong>调用关系说明：</strong></p>
<ul>
<li>0-服务容器负责启动，加载，运行服务提供者。</li>
<li>1-服务提供者在启动时，向注册中心注册自己提供的服务。</li>
<li>2-服务消费者在启动时，向注册中心订阅自己所需的服务。</li>
<li>3-注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li>
<li>4-服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>5-服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li>
</ul>
          <div class="post-more-link text-center">
            <a class="btn" href="/2016/07/01/(7.1).分布式架构-dubbo/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/metor.ico"
               alt="Pedestrian" />
          <p class="site-author-name" itemprop="name">Pedestrian</p>
          <p class="site-description motion-element" itemprop="description">study for goal</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">35</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">48</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yanan0628" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://carlosfu.github.io/" target="_blank" title="fudada">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  fudada
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://jolinzhangg.github.io/" target="_blank" title="xiaodada">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  xiaodada
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Pedestrian</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  



  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').mousedown(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>

  

  

  

</body>
</html>
